[
["index.html", "Introduction to R About this course Intended Learning Outcomes What will I need to complete this course? About the Assessments Assistance Why are these materials open?", " Introduction to R Gaby Mahrholz, Rebecca J. Lai, Kate Haining, Greta Todorova, and Wilhelmiina Toivo 2020-01-10 About this course This course is a short introduction on using R for dealing with data. Intended Learning Outcomes The Intended Learning Outcomes (ILOs) for the entire course are: To not be scared To be encouraged To get (a little bit) good Each chapter contained within will come with its own specific ILOs which will be clearly specified at the top of each page. These ILOs will be the points that will be covered in the assessments. What will I need to complete this course? To successfully complete this course you will need access to a computer that either already has, or you can download R and RStudio software on. This computer will need to use a Windows, Mac or Linux based operating system. You can run RStudio on a Chromebook sometimes, but the process is more complex (see here). If you cannot use RStudio on your computer you might want to consider using RStudio Cloud. All University of Glasgow Library computers should have this software installed. If you have enrolled in the University you should have access to these. After the first lesson you will be given the task of either installing R and RStudio on your own personal computer, or finding another suitable method of accessing the software. If you are having issues with access talk to your tutors via the Moodle forum as soon as possible so that we can help you! R, like any skill, will get better with practice and we want to ensure you can practice and complete the asessments as easily as possible. About the Assessments Formative Assessments These assessments allow you to revise the concepts that you have learned in class. These do not count towards the course grade and, although we encourage you to, there is no requirement to complete them. These may take the form of coding assessments or multiple choice questions (MCQs) that will be delivered through the Moodle site that you have been enrolled in. Summative Assessments These are the assessments that count towards your course grade. There will be 5 take-home exercises to complete as you progress through this course. They will be evenly spaced across the entire 10 week span, occuring every two weeks. You will have one week from the time of the release of each assessment to submit your answer(s). We will never ask you to memorise any code as this is not how people produce code in reality. You may use notes and resources you complete in class to do these assessments and consult online resources to help you. You can work together to complete these tasks, but remember that grades are given on an individual basis and that you must not plagiarise the work of others. For the purposes of your final grade only 4 of these assessments will be counted and each will be worth 25%. The lowest score out of the 5 assessments will be dropped and not taken into account when calculating your final grade. We encourage you to complete all 5 assessments. Each assessment will have between 3 and 5 questions for you to complete. Assessment 1 This will assess the ILOs taught in the first two classes covering the basics. Assessment 2 This will cover the ILOs taught in the third and fourth class, but you will also need to use knowledge from previous lessons as your learning is supposed to be cumulative. Assessment 3 This will cover the ILOs taught in the fifth and sixth class, but you will also need to use knowledge from previous lessons as your learning is supposed to be cumulative. Assessment 4 This will cover the ILOs taught in the seventh and eighth class, but you will also need to use knowledge from previous lessons as your learning is supposed to be cumulative. Assessment 5 This will cover the ILOs taught in the nineth and tenth class, but you will also need to use knowledge from previous lessons as your learning is supposed to be cumulative. How to Submit Your Assessments A file to complete each summative assessment will be provided to you. In this file you will be provided with code chunks in which to type your answers. Once you have provided code in all of the appropriate slots you will then upload this file to the assignment submission page on Moodle. MCQs MCQ assessments will be posted on the Moodle page for this course. You will see a selection of questions and will be asked to select the correct answer from a dropdown list of possible answers. Submitting these assessments will require you to select an answer for each of the questions and then press the “submit” button at the bottom of the page. MCQ assessments will always be formative, completely optional and will not contribute to your final grade for the class. However we do encourage you to try them as practice for the summative assessments. You may need to create some code in order to generate the answers to the MCQ questions. Coding Assessments Coding assessments will be uploaded to Moodle under your account. You should upload the file with the extension “.Rmd”, and not any files ending in “.R”/“.r”, “.txt”, “.csv” or “.html”. Coding assessments will be a mixture of formative and summative. Summative assessments will be clearly marked as such. Assistance You can ask questions on the Moodle page that accompanies this course. We ask that you do not post solutions to assessments here and any solutions posted will be removed. Why are these materials open? These materials have been adapted from various sources. Some of these materials have been Open Educational Materials with CC-BY-SA licenses. This means that any materials that use them must also be made open (SA means “share alike”). We also believe in the value of open educational materials. Your course fees contribute to the development of this course, but also to providing you with supporting staff and certification at the end of the course. "],
["introduction.html", "Chapter 1 Introduction Intended Learning Outcomes 1.1 Computer Literacy Basics 1.2 R and R Studio 1.3 R, R Studio and Associated File Types 1.4 Comments 1.5 Saving your file 1.6 Sessions 1.7 Packages 1.8 Functions 1.9 Formative Assignment", " Chapter 1 Introduction Intended Learning Outcomes By the end of this session you should be: Familiar enough with a computer to open, save and access previously saved files. Able to describe R and Studio, the coding environment and the associated file types. Able to install, load and describe the nature of R packages and describe the nature and use of functions in general. 1.1 Computer Literacy Basics In order to successfully navigate this course there are a number of things that you need to know about computers more generally. This section here should be everything that you are required to know or learn. We are aware that many people will have been using computers for many years, and in some cases many people will have grown up with them in their household. We have noticed, however, that a number of our incoming students are not familiar with many of the basic concepts that are required to be a successful coder. There is an assumption that “digital native” automatically equates to “computer literate” but in many cases we have found this assumption to be incorrect. More people than ever before are using some sort of personal computing device, but the type of use differs greatly from what we are going to be doing over the next 10 weeks. Many mobile phones, tablets and (increasingly) PC operating systems hide many of their operations from users. This can create a feeling of compentency with computers that can quickly dissolve when asked to engage with anything slightly more complex. 1.2 R and R Studio Are they different? Yes! Is this important? Yes! 1.2.1 R R is a programming language and completely free software, and it is widely used for data analysis. It is a stand-alone program and can be run on it’s own without R Studio, but it’s not particularly user friendly. 1.2.2 RStudio IDE RStudio IDE (short for Integrated Development Environment) is essentially a shiny facade, which sits atop R and gives it all sorts of useful features and makes it much easier to use. When you first open it you get 3 main panels, which can be seen in the picture below. 1.2.2.1 Console This is essentially the same thing as R commander. You can run code in here, and it can be a useful playground to try out new things and do things that you don’t neccessarily want saved into a script because it’s not permanent- anything typed here will be lost when you close R! Examples of things you might want to run in the console include, but are not limited to, running new functions and seeing what they do, or installing packages (never EVER done in a script). This is what the console looks like before you have run any code: 1.2.2.2 Environment/History/Connections This panel is tabbed, with 2 tabs that you need to pay particular attention to right now: Environment: this contains all of the virtual “objects” that you have created. These include, but are not limited to, variables containing data that you have read in, lists, individual values, custom-written functions. Objects can and should be created in your scripts. When you close R you might lose some of the objects, but as long as you have the script containing the instructions to re-create these objects you can re-run it and make them again. History: this is a list of all of the commands that you have run in the past “session”, which can be useful to go back to some times if you did run some code in the console that you want to look at again. To scroll through you can put the cursor in the console window and use up and down keys. At this point you don’t really need to worry about the one called connections (it lets you connect to things like online data sources and stuff). This is what that panel looks like for me right now… it’s empty! 1.2.2.3 Files/Plots/Packages/Help/Viewer This panel set is going to be mega-useful to you throughout the duration of your career as an R user. Viewer is not immediately required, so we’ll just cover Files, Plots, Packages and Help. Files: Shows a file browser that let’s you look around in your file structure. helpful hint: click on the more button and “Go to working directory” to see the same files that R can see. You can load files in through this tab, but you should always strive to do it in the script! Plots: A tab that displays plots that you have made. You can navigate backwards and forwards between multiple plots- allowing you to test out new things and see the changes in comparison to each other. Packages: This allows you to look at the R packages that are installed on the machine that you are using, and the check box next to it indicates if it is loaded in from the library. You can click the box to load a package, but you should always strive to do it in the script! Help: this window displays the built in help information, much the same as Microsoft Word or Powerpoint has. You can search using the search box, but you can also type into the console. For example, if I wanted to find the help file for the library() function I would type ?library. the result is displayed in the help tab to the right. Alternatively, you can type the name of the function you want help with into the search box in the help tab: Sometimes these files are not exactly written in a manner that could be considered accessible to novice users. You get the hang of reading them over time. In this case you might want to try Googling it… we all do it, no matter our level of experience! Even Googling can be difficult, but you will eventually get a better idea of the types of search terms most likely to direct you to the information that you are after. 1.3 R, R Studio and Associated File Types When you open a program, such as Microsoft Word, you haven’t actually created a Word document you’ve just started the program. Opening RStudio is much the same. Even though it can function without opening a file, there is much utility to be added by opening a file. When you open a file, the console will shrink and the space taken away in the window will be taken up by the new file. Opening a new file allows you to write code that can be saved, amended, shared etc. Code sharing is an important aspect of reproducibility! R can handle a lot of different files types, we will only focus on the two kinds that we learned about in the first semester. These are .r and .Rmd files. Both are saved as plain text files. Many of the files R uses are plain text files at their core. What changes is how R interprets the files, and the types of outputs that you can get from them. 1.3.1 File Structure/Directories Your files should be stored in something called “directories”. This is the technical name for a folder. It is a storage space on your computer. Here you can see all of the files contained within the folder for this course document in the “File Explorer”, the programme used to view files and folders in Windows: Each folder and the files within will have a specific “file path”, an address within your file storage system that allows you and the computer to pinpoint the location of the information that you and it need to perform tasks involving that file. In windows you can get the file path of a folder by clicking on the bar at the top of the folder when you are looking in it in the file explorer: This will be neccessary later when you start to use RStudio in conjunction with external files, such as data files. 1.3.2 File Extensions Files come in different types, and each different type comes with a different file extension, meaning that it is associated with a different type of program. A file extension is that part after a full-stop in the file name. Some common ones are: .xlsx: a spreadsheet file associated with Microsoft Excel .docx: a formatted text document associated with Microsoft Word .pdf: a Portable Document File, commonly text and images, associated with Adobe Acrobat .txt: a plain text file, can be opened in multiple programs such as Notepad or other word processing software. .zip: a compressed folder which can contain many files. These files must be uncompressed/extracted before you use them successfully. 1.3.3 .zip Files In this course we will often ask you to download a folder with multiple files and this will be stored on the server as a zip file. A zip file is a folder that contains files that have been compressed to make the file size smaller and enables you to download multiple files at once, however, before you use the files from a zip folder you first need to extract them. Click on the link to download the compressed folder. Navgiate to the zip file (probably in your downloads folder) and open it. You will see all the files it contains but don’t use these - click “Extract all” on the top ribbon. You will be asked to select a location to save the unzipped files. Normally the default location it suggests will be the same folder and so you can just click “Extract”. If you want to unzip these files to a different place click browse and select the folder you want to keep it in. I like to keep all the files for one project in the same folder. You can now delete the zip file and use the unzipped files. This is a really important step - if you use the compressed files your code may not work properly. This usually causes error messages relating to temporary files. Adapted from Level 1 Data Skills, (Nordmann and Woods 2019). 1.3.4 RStudio Specific Files RStudio uses many different types of files, but each is a variation on a “plain text” file. This means that all files we will be using in class will be able to be opened in Notepad or other similar text programs. The three main ones we will be working with will be: .r: an R script .Rmd: an RMarkdown document .csv: Comma Separated Variable document, a common and universal type of file containing data sets. If the file extension on a file is incorrect it may not be recognised as a file to be opened with a specific program and might not work. This is particularly an issue when you are downloading your files for class. As they are technically “plain text” files, some internet browsers will download them with the extension “.txt”, or even add it on as a second one which doesn’t work! Changing the extension to “.Rmd” or removing the extra added one will solve this issue. 1.3.5 .r Files This is what we refer to as a script. It is designed to be read by R, not so much by humans. To create a new script go to File &gt; New File &gt; R Script. This is what will be brought up: All of the text in an R script will default to being read as executable code (that is, text which is directed at the machine). We can, however, tell R not to read it as executable code, but instead for the machine to ignore certain parts of it, by using something called comments- you will read more about these below. 1.3.6 .Rmd files These are the types of files that you will mostly be using during this class. You will be given some pre-formatted ones to complete your assessments on also. When you go to File &gt; New file &gt; R Markdown… you will be prompted to supply some information. You can do this, but don’t have to as you can change many of these parameters later: When a new RMarkdown file is opened the file isn’t empty. What you actually get is an example with a YAML header (at the top bordered with the dashes), some code chunks (in the shaded sections, more on these in a minute), text and some headers (the hashtagged blue text outside of chunks). I like to think of the way this file type is interpreted as being like a script, but flipped- the default interpretation of text aimed at humans. If we want executable code we need to prompt R to read the text in this way. This is done using “code chunks”, or sometimes just called “chunks”. 1.3.6.1 Code Chunks Code chunks are bordered by “backticks”, which look an awful lot like apostrophes but they are different! These are important as they tell R where it needs to start and stop reading. Chunks also contain “curly brackets” at the start which contains various bits of information neccessary to how the computer reads it. This includes what programming language you are writing in there (yes! R can understand other programming languages!), name of the chunk (used for a variety of reasons, such as our marking software and document indexing) and other attributes which are not neccessary to learn about right now. The chunk must have the backticks to show the beginning and end of the executable code, otherwise the code doesn’t run. You must not add any code or text to the lines which contain backticks other than the code to alter the attributes of the chunk within the curly brackets (and only if you know how to do so). If you do this the code will not run and other chunks in the document might also be affected. Hastags used inside of code chunks don’t result in headers, but rather are ignored as the comments discussed in the section about .r files. 1.4 Comments Comments can- and should- be used throughout both .r and .Rmd file types. These are anything written after a hashtag symbol (and, if using a .Rmd file, within a code chunk). This symbol instructs the computer to disregard this text, letting it know that this is not for it to interpret as exectuable code but rather it is something for the human user to read and interpret. These are handy for letting others know what each piece of code was written to do, or to inform your future self of what you were doing. Make use of comments in the code we write in class and let this function as your class-notes. # this is what a comment looks like. Anything AFTER a hashtag. # R doesn&#39;t &quot;speak&quot; natural languages so it would not be able # to understand any of this and would give errors! # comments are for humans. You can use them to put notes in scripts to # remind yourself of what is happening, or to inform people with whom # you have shared your code. 1.5 Saving your file As mentioned before, anything in the console vanishes when you close R. Any objects that you have used code to make (those things that live in the environment) should vanish too. Your script is a set of instructions on how to make those objects. If you have saved your script or markdown, you can essentially re-run it and get back to where you left off when you last saved your progress. Saving your file for the first time is as easy as going to File &gt; Save As and filling in the details in the dialogue box as appropriate: Saving changes to an already existing file is done by going to File &gt; Save: 1.6 Sessions 1.6.1 What is a session in R? A session in R is a segment of time/workspace/processor time that is dedicated to performing a specific processing or analysis task. It can be difficult to wrap your head around at first, but it helps to draw comparisons with software that we are already familiar with. Let’s go back to Microsoft Word. We can have an essay open in one window and class notes opened up in another window. Both are instances of Word, but they are dedicated to two different tasks which just so happen to be running concurrently. You can have multiple sessions open in R, but I wouldn’t recommend it because it can become confusing. We can start a new session by going to Session &gt; new session. We Are much more interested in a task which is closely linked to this idea- restarting your current session. 1.6.2 Restarting Your Current Session This can be done by going to Session &gt; Restart R, see the image above. Restarting your R session does some important things: it clears the environment of objects if R is set up in a maximally reproducible way- so make sure your script is saved so that you keep the instructions for making them again it “unloads” packages that you have called from the library using the library() function If you encounter an error with an unknown source sometimes restarting the session can clear the problem It allows you to test the reproducibility of the script that you are writing by clearing the environment and starting over with only the instructions you have provided, without the possibility of “contamination” of objects inadvertently created in other ways, such as playing in the console 1.7 Packages R is a programming language which is primarily used for data processing and analysis. As the software is open source a number of people have created extensions to the software to adapt it to their needs. These software extensions are referred to as “packages”. 1.7.1 Installing Packages There are a number of functions that we will be using in this course that are not part of the original programming language. The most common package we will be using will be one called “Tidyverse”. We will use the example of Tidyverse to show you how to install packages that you might need. 1.7.1.1 What is Tidyverse? Do not install any packages on the university machines. All the packages you need are already installed. You would only need to install packages if you are using your own machine. You must also never place install.packages() in any r script or RMarkdown document: installing it a second time can break the installation and by sharing this script you would be attempting to force others to install it on their machines. This is at best rude and at worst it can break their installation. Tidyverse is a “metapackage”- a package that is actually a collection of packages that have been bundled together. It was developed by Hadley Wickham. You can read more abut the package here. 1.7.1.2 install.packages() When you install a package, you should do this in the console part of the interface, as shown here: Types the following in and then hit “enter”: &gt; install.packages(&quot;tidyverse&quot;) Note that the name of the package is in quotation marks when used here. This is not always the case! The console will then fill with a lot of text showing you what is being done. It is not neccessary to understand all of this. Look out for this message being printed in the console This indicates that the package has been installed successfully. There will be many of these messages for different packages. There may even be parts after this message if the computer determines that other “dependencies” (additional software that tidyverse requires to run) are required. Once R has stopped working (doing it’s current task) the &gt; will reappear in the console. This symbol reappearing means that R is ready for further code. To install other packages you would reuse the function install.packages(), replacing the name “tidyverse” with the name of the package you want to install. We will cover functions shortly. 1.7.2 Loading Packages Now that we have installed Tidyverse it is on our machine but it is not ready to use yet! It is easier to understand if you think about it like this: if you install Instagram on your phone you only do it once and you have to open the app each time you want to use it. Similarly, once Tidyverse is installed it is on your computer until you remove it. If you want to use it you need to “open it”. This is done by using another function, library(). library(tidyverse) This must be done before you use Tidyverse. We normally do this in the first chunk in the document, essentially gathering our tools before we start working. If you want to load other packages you would reuse the function library(), replacing “tidyverse” with the name of the package you want to load. 1.8 Functions “Function” is a word that you will hear a lot in this class. But what are they? What do they look like? what are they made up of? 1.8.1 What is a function? If I were to tell you to jump, you would understand the action I was asking you to perform wouldn’t you? But before you carry it out you might ask me a question in return: how high? This is what a function is for R… it’s a command that tells R to do something. It just does it in a way that R understands. 1.8.2 The Anatomy of a Function: names and arguments Functions are made up of elements. See the code chunk below: function_name(argument1, argument2, etc...) The part outside of the brackets is the name of the function. This tells R exactly what to do- the action to be performed. The parts inside the brackets are called arguments… these provide information to R on what to perform the actions on (and input) and can provide information on slight changes to the actions. Essentially the function name is the action to perform (jump) and the arguments give information on how to perform the action (how high). Think about install.packages(“tidyverse”) and library(tidyverse): what are the function names and what are the arguments? Which part changes when you want to install and load a different package? Once your function has taken the input and run the command on it it will produce an output of some sort. As we progress through this course see if you can spot the functions, the arguments, the inputs and the outputs. 1.9 Formative Assignment This formative assignment is an important one as it will enable you to complete your future assignments. It looks long, but it is mostly screenshots to guide you through the process of installing the required software, or a short guide on how to use RStudio Cloud. 1.9.1 Access to RStudio Please ensure by the next class that you have access to the software so that you can practice using the formative assignments and complete the summative assignments when they are issued. The first summative assignment will be issued after class next week and you will be given one week to complete and submit it. 1.9.1.1 Installing R and RStudio on Your Own Machine Unfortunately this is not as simple as installing software normally is on your computer. There are two separate things that you will need to install. 1.9.1.1.1 First: Install R 1.9.1.1.1.1 Windows Users Follow this link and click on the part that says Download R 3.6.2 for Windows. You will get the following pop-up dialogue: Click “Save File”. The file will then be downloaded to your computer, most likely the “Downloads” folder unless you have changed your settings. Double click to run the file. You will be asked if you want to allow this to make changes to your computer, click yes. Select your language preference, review the license agreement and click next. The following screen will be presented: Click next without changing the folder. The next screen let’s you customise the installation, but we shouldn’t need to make any changes at this point so click next without unselecting any components: Also leave the star-up options as standard and click next: Leave the start menu folder as standard: Don’t make any changes to the additional tasks part, just click next: The Install Wizard will then install R: You will be told when installation is complete: 1.9.1.1.1.2 Mac OS Users 1.9.1.1.2 Second: Install RStudio 1.9.1.1.2.1 Windows Users Follow this link to the RStudio website. Scroll down and press the button “Download” under RStudio Desktop- not the Server Option. On the next page press the button under stage 2, “Download RStudio for Windows”. Your download will start and you will see the following prompt: Click “Save File” when the button becomes active. Look in your download folder and double click the downloaded file. Click to allow the program to make changes to your computer. You will see this part next: Click next on this next window. Do not change the installation location. Click next: You will be taken to this screen. Again, don’t change the start menu folder location here. Click next and the installation will begin: You will then be notified when the installation is complete with this screen: 1.9.1.1.2.2 Mac OS Users 1.9.1.1.3 Opening RStudio Remember that we have installed two programs on our computer. R, which is the base program, and RStudio, which is an extension of R. The software that we want to open and use is RStudio, not R. We want the shiny interface and added features. 1.9.1.2 Accessing RStudio on University Computers If you have a student card you will be able to access computing facilities provided for students, including those in the various libraries across campus. All university computers should have R and RStudio installed, as well as the required packages for this course. You will not be required to install anything on university computers, please don’t attempt to do so because we don’t want the IT guys to yell at us. To login to the university computers you will require your GUID and password. 1.9.1.3 Using RStudio Cloud We recognise that not all students will have access to their own computers, and that some of those students will not be able to travel to campus to use the provided facilities. For this reason we recommend to those in that postition to think about using RStudio Cloud, available here. The RStudio Cloud allows you an electronic workspace, hosted by the RStudio team themselves. Navigate to the page and click the “Sign Up” button at the top right-hand side of the page. Once you are logged in you will see your (for now) empty workspace: Click on “new project” and you will be taken to this page: As you can see it is almost identical to the way the program would appear on your computer if you had installed it there. To name your project you can click the name at the top of the page and type in a new one: You will also need to upload any data files to the server before you can work with them. This is done with the addition to the panel Files/Plots/Packages/Help/Viewer on the right- the “Files” pane now had a button to upload: Pressing this will open a pop-up box. Click on the “browse” button, navigate through your directories and identify the file you wish to upload and confirm. Then press ok. The file should then be uploaded and displayed in the files pane. If at any point you are struggling to access the required materials or software it is important that you contact the tutors at the earliest opportunity to discuss the issues you are having. We want you to do well and have a good experience learning with us, let us know if you are experiencing difficulty so that we may help you resolve it! 1.9.1.3.1 Downloading Your Files from RStudio Cloud If you are using RStudio Cloud your files will be saved on the cloud, but you will need to download the .Rmd files that you have been working with (containing coursework etc) to upload them to the assignment submission pages on Moodle. Here you can see the file myfile.Rmd that I have made on the cloud. To download it I select the checkbox next to the file and click on the “More” drop-down menu and click “export”, as shown here: I then get a dialogue box asking me if I want to name the file something different. I will stick with the original name, so I just click “Download”: Now I get a pop-up as I would when downloading any other file. To save the file ensure “Save File” is selected and click “OK”: The file will then be saved in the folder where your downloads are saved (usually the “Downloads” folder by default). You can then navigate to this file when browsing files to upload to Moodle. 1.9.2 Installing and Loading Tidyverse Use the information in the section 1.7.1.1 above to install the Tidyverse package on your RStudio installation. If you are using RStudio Cloud you are provided with a completely self-contained computing environment. This means that you can install.packages() on your virtual RStudio too as required. Load Tidyverse from the using the library() function in section 1.7.2. For now you can do this in either a new .r file, .Rmd file or even in the console. If you successfully load it you will see this printed in the console: You will be using the Tidyverse package in the next lesson, so don’t worry if you struggle with this at the moment. References "],
["introduction-to-data.html", "Chapter 2 Introduction to Data Intended Learning Outcomes 2.1 Pre-Steps 2.2 Basic data types 2.3 Vectors 2.4 Tibble - the new way of creating a dataframe 2.5 Reading in data 2.6 Last point for today 2.7 Summative Homework", " Chapter 2 Introduction to Data Intended Learning Outcomes understand basic data types create and store vectors convert data types into one another create a data table from scratch import and store data TAKE OUT LATER ON - just examples of what boxes exist for the minute {block, type = “solved”} {block, type = “funfact”} {block, type = “question”} {block, type = “info”} {block, type = “danger”} {block, type = “warning”} {block, type = “task”} 2.1 Pre-Steps Before we begin, we need to do some house-keeping. 2.1.1 Downloading materials First, we need to download the materials we are working with today. You can find them here or on moodle. It’s a zip folder that contains an Rmd file called L2_stub and a data file in .csv format forlater. L2_stub has all the code chunks listed for today’s lesson. You are more than welcome to add notes and comments to the Rmd (white chunks), however there is no need to copy any code. 2.1.2 Unzipping the zip folder The folder we have downloaded is a zip folder. R cannot handle zip folders very well, so the folder needs to be unzipped. Right-mouseclick on the zipped folder, then choose Extract All.... Copy and paste/ move the folder to your M drive (or somewhere that makes sense to you - and where you can find it again - if you are using your own computer). Check the unzipped folder contains the L2_stub.Rmd and a data file called MM_data.csv. 2.1.3 Setting the working directory It is always good practice to set your working directory to the folder you are working with. This can be done in 2 ways: In the menu, go to Session &gt; Set Working Directory &gt; Choose Directory (Crtl + Shift + H also works as key short cut in a Windows environment). Then select the folder containing the data file and click ‘open’. You might not see any files in the folder you are selecting - that is fine. In the Files pane, you could navigate to today’s folder, and once there click on More &gt; Set As Working Directory. Whichever way you prefer is fine. The files L2_stub and MM_data.csv should now be visible in the Files pane. 2.1.4 Load tidyverse into the library We will be using a few functions today that are part of the tidyverse package compilation. Let’s load tidyverse in the library now, so we do not have to worry about it later on. library(tidyverse) Yay, with that out of the way, we can begin Lesson 2. 2.2 Basic data types There are plenty data types, however for our purposes we will be focussing on: data type description example character text string \"hello World!\", \"35.2\", 'TRUE' double double precision floating point numbers .033, -2.5 integer positive &amp; negative whole numbers 0L, 1L, 365L logical Boolean operator with only two possible values TRUE, FALSE 2.2.1 Character You can store any text as a value in your local environment. You can either use single or double inverted commas. my_quote &lt;- &#39;R is Fun to learn!&#39; cat(my_quote) # cat() prints the value stored in my_quote If you want to use a direct quote, you need to include a backslash before each inverted comma. direct_quote &lt;- &quot;My friend said \\&quot;R is Fun to learn\\&quot;, and we all agreed.&quot; cat(direct_quote) ## My friend said &quot;R is Fun to learn&quot;, and we all agreed. You can check the data type using the typeof() function. If you want to know which class they belong to, you can use the class() function. 2.2.2 Numeric double and integer are both class numeric. Double is a number with decimal places whereas integer is a number that’s a full number. Any number will be stored as a double unless you specify integer by adding an L as a suffix. Example: typeof(359.1) ## [1] &quot;double&quot; typeof(5) ## [1] &quot;double&quot; typeof(45L) ## [1] &quot;integer&quot; 2.2.3 Logical A logical vector is a vector that only contains TRUE and FALSE values. You can use that type of data to compare (or relate) 2 pieces of information. We have several comparison (or relational) operators in R. A few of them are: More information on logical comparison operators can be found on https://bookdown.org/ndphillips/YaRrr/logical-indexing.html (from which the above image was modified). You could compare if two values are equal… 100 == 100 ## [1] TRUE … or if they are not equal. 100 != 100 ## [1] FALSE We can test if one value is smaller or equal than the other… 5 &lt;= 9-4 ## [1] TRUE … or if one value is larger than another. 101 &gt; 111 ## [1] FALSE Note that it works with character strings as well. (Not really important for this class though) # &quot;a&quot; == &quot;a&quot; would be TRUE as both side of the comparison contain the same information. &quot;a&quot; == &quot;a&quot; ## [1] TRUE # &quot;a&quot; &lt;= &quot;b&quot; would be TRUE as a comes before b in the alphabet (i.e. 1st letter vs 2nd letter) &quot;a&quot; &lt;= &quot;b&quot; ## [1] TRUE # &quot;abc&quot; &gt; &quot;a&quot; would be TRUE as there are more values on the left than on the right &quot;abc&quot; &gt; &quot;a&quot; ## [1] TRUE Question Time Run the following examples in your Console and select from the drop down menu what data type they belong to: class(1): character double integer logical Error message class(1L): character double integer logical Error message class(1.0): character double integer logical Error message class(“1”): character double integer logical Error message class(1L == 2L): character double integer logical Error message class(1L &lt;= 2L): character double integer logical Error message class(1L &lt;= 2L, “1”): character double integer logical Error message Explain this - why is 1 not an integer? Any number will be stored as a double unless you specify integer by adding an L as a suffix. 2.3 Vectors Vectors are one of the very simple data structure in R. You could define them as “a single entity consisting of a collection of things”. 2.3.1 Creating vectors If you want to combine more than one element into one vector, you can do that by using the c() function. c stands for combine or as my colleague once said, it’s hugging multiple elements together. All elements in the vector have to be of the same data type. Examples: This is a vector of datatype double. c(1, 2.5, 4.7) ## [1] 1.0 2.5 4.7 typeof(c(1, 2.5, 4.7)) ## [1] &quot;double&quot; This is a vector of datatype integer. Adding the L makes it an integer, but see that in the printout the L is actually omitted. c(0L, 1L, 2L, 365L) ## [1] 0 1 2 365 typeof(c(0L, 1L, 2L, 365L)) ## [1] &quot;integer&quot; This is a vector of datatype character. c(&quot;hello&quot;, &quot;student&quot;) ## [1] &quot;hello&quot; &quot;student&quot; typeof(c(&quot;hello&quot;, &quot;student&quot;)) ## [1] &quot;character&quot; This is a vector of datatype logic. c(TRUE, FALSE) ## [1] TRUE FALSE typeof(c(TRUE, FALSE)) ## [1] &quot;logical&quot; We have seen what vectors look like. If you want to store these vectors in your global environment, all you need is the assignment operator &lt;- and a meaingful name for “the thing” you want to store. Here the first example reads like: “Take a vector of 3 elements (namely 1, 2.5, 4.7) and store it in your Global Environment under the name vec_double.” You can then use the name you assigned to the vector within the typeof() function, rather than the vector itself. vec_double &lt;- c(1, 2.5, 4.7) typeof(vec_double) ## [1] &quot;double&quot; vec_integer &lt;- c(0L, 1L, 2L, 365L) typeof(vec_integer) ## [1] &quot;integer&quot; vec_character &lt;- c(&quot;hello&quot;, &quot;student&quot;) typeof(vec_character) ## [1] &quot;character&quot; vec_logic &lt;- c(TRUE, FALSE) typeof(vec_logic) ## [1] &quot;logical&quot; Funnily enough, a vector i &lt;- c(1,3,4,6) would be stored as a double. However, when coded as i &lt;- 1:10 would be stored as an integer. Don’t believe it? Try it out in your Console! Question Time Your turn Create a vector of your 3 favourite movies and call it favourite_movies. What type of data are we expecting? Pick a couple of your family members or friends and create a vector years_birth that lists their year of birth. How many elements does the vector have, and what type of data are we expecting? Create a vector that holds all the letters of the alphabet and call it alph. Create a vector with 3 elements of your name, age, and the country you are from. Store this vector under the name this_is_me. What type of data are we expecting? Explain this! # Gaby&#39;s solution: favourite_movies &lt;- c(&quot;Red&quot;, &quot;Cloud Atlas&quot;, &quot;Hot Fuzz&quot;) # character years_birth &lt;- c(1953, 1975) # double alph &lt;- letters # muahahahaaaa! &amp; character this_is_me &lt;- c(&quot;Gaby&quot;, 38, &quot;Germany&quot;) # character More detailed explanations: R has Built-in Constants: letters: the 26 lower-case letters of the Roman alphabet; LETTERS: the 26 UPPER-case letters of the Roman alphabet; month.abb: the three-letter abbreviations for the English month names; month.name: the English names for the months of the year; pi: the ratio of the circumference of a circle to its diameter Of course, the task could have been solved typing alph &lt;- c(“a”, “b”, “c”, “d”, “e”, “f”, “g”, “h”, “i”, “j”, “k”, “l”, “m”, “n”, “o”, “p”, “q”, “r”, “s”, “t”, “u”, “v”, “w”, “x”, “y”, “z”) this_is_me would be stored as a character vector despite having text as well as numeric elements. Remember how we said earlier that all elements have to be of the same data type? After the next section, you will understand why they are stored as a character and not as a numeric vector. 2.3.2 Converting vectors into different data types of vectors aka funky things we can do We can also reassign data types to our vectors we have just created. For example if we wanted to turn our var_double from double to character, we would code vec_double_as_char &lt;- as.character(vec_double) typeof(vec_double_as_char) ## [1] &quot;character&quot; In your Global Environment, you can now see that the vector vec_double has 3 numeric elements (abbreviated num), whereas vec_double_as_char has 3 character elements (abbreviated chr). Also note that the numbers 1.2, 2.5, and 4.7 have now quotation marks around them. Likewise, if we wanted to turn our integer vector vec_integer into data type double, we would use vec_integer_as_double &lt;- as.double(vec_integer) typeof(vec_integer_as_double) ## [1] &quot;double&quot; In your Global Environment, see how vec_integer has int assigned to it, whereas vec_integer_as_double is now listed as num. The typeof function revealed that the 4 elements of vec_integer_as_double are now stored as data type double. However, trying to turn a character vector into an integer or a double would fail. vec_char_as_int &lt;- as.integer(vec_character) # same outcome if we tried as.double ## Warning: NAs introduced by coercion typeof(vec_char_as_int) ## [1] &quot;integer&quot; R would still compute “something” but it would be accompanied by the above warning message. As you can see in your Global Environment, vec_char_as_int does indeed exist as a numeric vector with 2 elements, but NA tells us they are classified as missing values. A logical vector can be converted into all other basic data types. vec_logic_as_int &lt;- as.integer(vec_logic) vec_logic_as_int ## [1] 1 0 TRUE and FALSE will be coded as 1 and 0 respectively when converting a logical into a numeric vector (integer or double). When converting a logical into a characters, it will just read as \"TRUE\" and \"FALSE\". vec_logic_as_char &lt;- as.character(vec_logic) vec_logic_as_char ## [1] &quot;TRUE&quot; &quot;FALSE&quot; Question Time Remember the vector this_is_me? Can you explain now why it was stored as character? Nope, I don’t get it! this_is_me would be stored as a character vector because this is the best way to retain all information. If this were to be stored as a numeric vector, the name and home country could only be coded as missing values NA. So rather than trying to turn everything into a number (which is not possible/ does not retain meaningful information), R turns the number into character (which is possible). With this in mind, what data type would the vector be stored as if you combined the following elements? logical and double - i.e. c(TRUE, 45) character and logical - i.e. c(“Sarah”, “Marc”, FALSE) integer and logical - i.e. c(1:3, TRUE) logical, double, and integer - i.e. c(FALSE, 99.5, 3L) Solution double character integer double 2.3.3 Adding elements to existing vectors Let’s start with a vector called friends that has three names in it. friends &lt;- c(&quot;Gaby&quot;, &quot;Wil&quot;, &quot;Greta&quot;) friends ## [1] &quot;Gaby&quot; &quot;Wil&quot; &quot;Greta&quot; We can now add more friends to our little group of friends by adding them either at the end, or the beginning of the vector. friends will now have four, and five values respectively, since we are “overwriting” our existing vector with the new one of the same name. friends &lt;- c(friends, &quot;Kate&quot;) friends ## [1] &quot;Gaby&quot; &quot;Wil&quot; &quot;Greta&quot; &quot;Kate&quot; friends &lt;- c(&quot;Rebecca&quot;, friends) friends ## [1] &quot;Rebecca&quot; &quot;Gaby&quot; &quot;Wil&quot; &quot;Greta&quot; &quot;Kate&quot; Vectors also support missing data. If we wanted to add “another friend” whose name we do not know yet, we can just simply add NA to friends. friends &lt;- c(friends, NA) friends ## [1] &quot;Rebecca&quot; &quot;Gaby&quot; &quot;Wil&quot; &quot;Greta&quot; &quot;Kate&quot; NA The vector friends would still be a character vector. Missing values do not alter the original data type. However, if you look in the Global Environment, you can see that the number of elements stored in friends increased from 5 to 6. To determine the number of elements in a vector in R (rather than eye sight), you can also use a function called length(). typeof(friends) ## [1] &quot;character&quot; length(friends) ## [1] 6 Well, now we decided that 5 friends in our little group of friends is sufficient, and we did not want anyone else to join, we could remove the “placeholder friend NA” by coding friends &lt;- friends[1:5] friends ## [1] &quot;Rebecca&quot; &quot;Gaby&quot; &quot;Wil&quot; &quot;Greta&quot; &quot;Kate&quot; You can see that the length of the vector friends is now back to 5 again. 1:5 uses the colon operator: which is read as in “access the vector elements 1, 5, and everything in between”. An alternative way of writing out the above without using a colon operator would be friends[c(1,2,3,4,5)]. Notice that you need the c() function again. Just as easily, we can create vectors for numeric sequences. The function seq() is a neat way of doing this, or you can use the colon operator: again. Just with the elements in the vector above, the same logic applies here. For example 1:10 means, you want to list number 1, number 10, and all numbers in between. sequence1 &lt;- 1:10 sequence1 ## [1] 1 2 3 4 5 6 7 8 9 10 sequence2 &lt;- seq(10) sequence2 ## [1] 1 2 3 4 5 6 7 8 9 10 # compare whether sequence1 and sequence2 are of the same data type typeof(sequence1) == typeof(sequence2) ## [1] TRUE # compare whether elements of sequence1 are the same as the elements in sequence2 sequence1 == sequence2 ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE Question Time What data type is sequence1? character double integer logical What data type is sequence2? character double integer logical If we were to store the output of sequence1 == sequence2 in a vector, what data type would the vector be? character double integer logical 2.4 Tibble - the new way of creating a dataframe 2.4.1 What the heck is a tibble? Do you mean table? First of all, tibble is not a spelling error; it’s the way r refers to its newest form of data table or dataframe. You can create a dataframe either by using the tibble() function or a function called data.frame(). tibble() is part of the package tidyverse whereas data.frame can be found in base R and does not need an additional package read into the library. Tibbles are slightly different to dataframes in that they have better print properties (Dataframes print ALL data when you call the data whereas tibbles only print the first 10 rows of data) character vectors are not coerced into factors (which you will be thankful for later on in your programming life) column names are not modified (for example if you wanted to make a column called Female Voices you could just do that. tibble keeps it as Female Voices with a space between the two words, whereas the data.table function would change it to Female.Voices) If you want to read more about the differences between dataframes and tibbles (and appreciate the advantages of tibbles), have a look on https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html. 2.4.2 How to make a tibble from scratch Now that you have learnt how to create vectors, we can try and combine them into a tibble. The easiest way is to use the tibble() function. Let’s say we want to create a tibble that is called tibble_year with 4 columns: The first column month lists all months of the year The second column abb_month gives us the three-letter abbreviation of each year. The third column month_num tells which number of the year is which month (e.g. January would be the first month of the year; December would be number 12). The fourth column season would tell us in which season the month is (Northern hemisphere). Remember the Built-in Constants we were talking about earlier? # Remember to load tidyverse into your script at least once (usually at the beginning) library(tidyverse) tibble_year &lt;- tibble(month = month.name, abb.month = month.abb, month_num = 1:12, season = c(rep(&quot;Winter&quot;, 2), rep(&quot;Spring&quot;, 3), rep(&quot;Summer&quot;, 3), rep(&quot;Autumn&quot;, 3), &quot;Winter&quot;)) tibble_year ## # A tibble: 12 x 4 ## month abb.month month_num season ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 January Jan 1 Winter ## 2 February Feb 2 Winter ## 3 March Mar 3 Spring ## 4 April Apr 4 Spring ## 5 May May 5 Spring ## 6 June Jun 6 Summer ## 7 July Jul 7 Summer ## 8 August Aug 8 Summer ## 9 September Sep 9 Autumn ## 10 October Oct 10 Autumn ## 11 November Nov 11 Autumn ## 12 December Dec 12 Winter The generic structure of each of these columns we are creating is column header name = values to fill in the rows. Here, we used the built-in replication function rep() to build the column season which is a more time-efficient approach than typing out 4 seasons 3 times. Of course, we could have written season = c(“Winter”, “Winter”, “Spring”, “Spring”, “Spring”, “Summer”, “Summer”, “Summer”, “Autumn”, “Autumn”, “Autumn”, “Winter”) instead. We can now use the function glimpse() to see which data types our columns are. This is a very handy function to keep in mind for later! glimpse(tibble_year) ## Observations: 12 ## Variables: 4 ## $ month &lt;chr&gt; &quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;, &quot;May&quot;, &quot;Jun... ## $ abb.month &lt;chr&gt; &quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Au... ## $ month_num &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ## $ season &lt;chr&gt; &quot;Winter&quot;, &quot;Winter&quot;, &quot;Spring&quot;, &quot;Spring&quot;, &quot;Spring&quot;, &quot;S... glimpse() tells us that our tibble has one column that is an integer, and three columns that are character strings. If we wanted to influence which datatype the columns (something that is not automatically assigned), we can do that by using the functions as.double(), as.character(), as.integer(), etc. we have seen earlier when we were talking about vectors. For example, if we wanted to modify the integer column as a double, we would type tibble_year2 &lt;- tibble(month = month.name, abb.month = month.abb, month_num = as.double(1:12), season = c(rep(&quot;Winter&quot;, 2), rep(&quot;Spring&quot;, 3), rep(&quot;Summer&quot;, 3), rep(&quot;Autumn&quot;, 3), &quot;Winter&quot;)) If you click on the name of the dataset in your Global Environment to view your dataframe, you would see no actual difference between tibble_year and tibble_year2. However, glimpse() would tell you. If I were a mean person, and had recoded month_num = as.character(1:12) instead, you would not see it when you visually inspect the data. What would the consequences be? Question Time Your turn Make a dataframe called mydata with 5 columns and 10 rows: column 1 is called PP_ID and contains participant numbers 1 to 10. Make sure this data type is integer. column 2 is called PP_Age and and contains the age of the participant. Make sure this data type is double. column 3 is called PP_Sex and contains the sex of the participant. Even PP_IDs are male, odd PP_IDs are female participants. column 4 is called PP_Country and contains the country participants were born in. Surprise, surprise - they were all born in Scotland!!! column 5 is called PP_Consent and is an overview whether participants have given their consent to participate in an experiment (TRUE) or not (FALSE). Participants 1-9 have given their consent, participant 10 has not. Solution # Gaby&#39;s solution: mydata &lt;- tibble(PP_ID = 1:10, PP_Age = c(22, 21, 24, 36, 33, 25, 21, 31, 28, 35), PP_Sex = rep(c(&quot;Female&quot;, &quot;Male&quot;), 5), PP_Country = &quot;Scotland&quot;, PP_Consent = c(rep(TRUE, 9), FALSE)) But there are plenty of other ways how this could have been done. For example: PP_ID = seq(10) PP_ID = as.integer(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) PP_Age = as.double(22:31) PP_Sex = c(“Female”, “Male”, “Female”, “Male”, “Female”, “Male”, “Female”, “Male”, “Female”, “Male”) PP_Country = rep(“Scotland”, 10) PP_Consent = c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE) 2.5 Reading in data 2.5.1 from pre-existing databases R comes with pre-installed datasets available for you to use and practice your skills on. If you want have an overview over all databases available type data() into your Console. One of those datasets is called “Motor Trend Car Road Tests” or in short mtcars. If you type mtcars into your Console, you can see what the dataset looks like. mtcars ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 You can look up what all the column headers mean by typing ?mtcars into your Console, or using the help tab to search for mtcars. mtcars is a dataframe rather than a tibble. How do we know that? Answer When we called mtcars it printed the whole dataframe rather than just the first 10 rows. However, we have seen what the data in mtcars looks now, but we would be able to work with it better if put it into our Global Environment. Let’s save mtcars as a dataframe called data_mtcars, and look at the first few rows which can be achieved using the head() function. data_mtcars &lt;- mtcars # read in as a dataframe head(data_mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Notice that we do not have a column header for the type of car. The reason is that the type of car is actually the name of the rows, rather than a column itself. As you can see in your Global Environment, df_mtcars has 32 observations, and 11 variables - car type is not one of them. Adding the rownames as a separate column would be rather tricky at this stage in the course (but you could try and do it after lecture 5). Another interesting dataset is called starwars. It can be found in the package dplyr which is part of tidyverse. So, as long as you have tidyverse loaded into your library, starwars should be available to you. library(tidyverse) # if you have already done this in your Rmd, this step is superfluous starwars ## # A tibble: 87 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke~ 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl~ red 33 &lt;NA&gt; ## 4 Dart~ 202 136 none white yellow 41.9 male ## 5 Leia~ 150 49 brown light brown 19 female ## 6 Owen~ 178 120 brown, gr~ light blue 52 male ## 7 Beru~ 165 75 brown light blue 47 female ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; ## 9 Bigg~ 183 84 black light brown 24 male ## 10 Obi-~ 182 77 auburn, w~ fair blue-gray 57 male ## # ... with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, ## # species &lt;chr&gt;, films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; In comparison to mtcars, starwars is already a tibble (which you can see in the first line of the printout). It gives you the number of observations (87) and variables (13), the column headers, the data type of each column, and the first 10 rows of data. Again, it would be neater to work with the data if we saved the data tibble to our Global Environment. Let’s do that and call it data_SW. data_SW &lt;- starwars Again, you could use the very handy glimpse() function to see what data types the columns are. glimpse(data_SW) There are other built in datasets available, such as babynames. The babynames dataset is located in a package called babynames which needs to be installed first, and then loaded into the library before you can look at the data. Do you remember how we install packages and load them into the library? Hint install.packages(“babynames”) library(babynames) Remember that you only have to do the install.packages(“babynames”) once - before you want to use babynames for the very first time. Once you have installed it, you can use it whenever you feel like by just loading it into the library. 2.5.2 from existing data files R is able to handle different types of data files. The most common one available is .csv. CSV stands for comma-separated values. Usually, a .csv file is opened with some sort of excel programme (like Microsoft Excel, LibreOffice, OpenOffice, Apple Numbers, etc.) which takes the comma separator as a mean to format everything into a nice and neat table. If you open your data in Notepad, you can actually see the structure of it. There are other file types out there, apart from csv, like tsv (tab-separated values), excel, SAS, or SPSS. However, these would go beyond the scope of this class. All of our data will be in a .csv format. Getting the data from the csv file into your Global Environment in R is by using a function called read_csv() from the package tidyverse. Since we did the house-keeping (i.e. loading in the package tidyverse into the library) at the very beginning, there is no need for us to do that again. The data you just saw in the screenshot above are from M&amp;Ms colours by bag (http://www.randomservices.org/random/data/index.html). The data table gives the color counts and net weight (in grams) for a sample of 30 bags of M&amp;M’s. The advertised net weight is 47.9 grams. MM_data &lt;- read_csv(&quot;MM_data.csv&quot;) ## Parsed with column specification: ## cols( ## Red = col_double(), ## Green = col_double(), ## Blue = col_double(), ## Orange = col_double(), ## Yellow = col_double(), ## Brown = col_double(), ## Weight = col_double() ## ) As you can see, R is giving you a bit of an output of what it has just done - parsed some columns. The data is stored as an object in your Global Environment now, and we could either call the data (by typing MM_data into the Console) or use glimpse() to have a look what the data actually looks like and what data types are in each column. MM_data ## # A tibble: 30 x 7 ## Red Green Blue Orange Yellow Brown Weight ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 15 9 3 3 9 19 49.8 ## 2 9 17 19 3 3 8 49.0 ## 3 14 8 6 8 19 4 50.4 ## 4 15 7 3 8 16 8 49.2 ## 5 10 3 7 9 22 4 47.6 ## 6 12 7 6 5 17 11 49.8 ## 7 6 7 3 6 26 10 50.2 ## 8 14 11 4 1 14 17 51.7 ## 9 4 2 10 6 18 18 48.4 ## 10 9 9 3 9 8 15 46.2 ## # ... with 20 more rows glimpse(MM_data) ## Observations: 30 ## Variables: 7 ## $ Red &lt;dbl&gt; 15, 9, 14, 15, 10, 12, 6, 14, 4, 9, 9, 8, 12, 9, 6, 4, ... ## $ Green &lt;dbl&gt; 9, 17, 8, 7, 3, 7, 7, 11, 2, 9, 11, 8, 9, 7, 6, 6, 5, 5... ## $ Blue &lt;dbl&gt; 3, 19, 6, 3, 7, 6, 3, 4, 10, 3, 13, 6, 13, 7, 6, 9, 11,... ## $ Orange &lt;dbl&gt; 3, 3, 8, 8, 9, 5, 6, 1, 6, 9, 0, 5, 2, 2, 4, 4, 12, 6, ... ## $ Yellow &lt;dbl&gt; 9, 3, 19, 16, 22, 17, 26, 14, 18, 8, 7, 11, 6, 18, 21, ... ## $ Brown &lt;dbl&gt; 19, 8, 4, 8, 4, 11, 10, 17, 18, 15, 18, 20, 13, 7, 13, ... ## $ Weight &lt;dbl&gt; 49.79, 48.98, 50.40, 49.16, 47.61, 49.80, 50.23, 51.68,... You could also have used the function head() to show the first 6 rows of the dataframe or could have viewed the data by clicking manually on MM_data in the Global Environment. Watch out, though!!! head() can be a bit misleading in that it creates a new tibble and the output reads # A tibble: 6 x 7. This does not mean that our MM_data only has 6 rows of observations!!! Viewing the data opens the data in a new tab in the Source pane but it does not show you the data types of the columns. You could, however, click on the wee blue arrow next to the data name. Now that we have inspected the data, what does it actually tell us? Question Time How many rows (or observations) does MM_data have? How many columns (or variables) does MM_data have? What data type are all of the columns? character double integer logical Always use read_csv() from the tidyverse package for reading in the data. There is a similar function called read.csv() from base R - DO NOT USE read.csv(). These two functions have differences in assigning datatypes to the columns and read_csv() does a better job. This applies to the homework task as well. You will not receive marks if you are using the wrong function. So double check before submitting!!! 2.6 Last point for today Knit your L2_stub. If it knits, it is an indication that all your code chunks are running. This is important for most of the graded assessments in the future. If it runs on your computer, it will run on ours. 2.7 Summative Homework The first summative assessment is compiled of 11 questions from Lectures 1 and 2. You can download the files from moodle. The folder you download is a zip folder that needs to be unzipped before you can work with it. It contains the homework submission file labelled GUID_L1L2.Rmd and a data file called TraitJudgementData.csv. Good luck. Check that your Rmd file knits into a html file before submitting. Upload your Rmd file (not the knitted html) to moodle. "],
["data-transformation-1-basic-one-table-verbs.html", "Chapter 3 Data Transformation 1: Basic One Table Verbs Intended Learning Outcomes 3.1 Data Wrangling 3.2 Pre-Steps 3.3 Select() 3.4 Arrange() 3.5 Filter() 3.6 Mutate() 3.7 Formative Homework", " Chapter 3 Data Transformation 1: Basic One Table Verbs Intended Learning Outcomes Be able to use the following dplyr one-table verbs: select() arrange() filter() mutate() 3.1 Data Wrangling It is estimated that data scientists spend between 50-80% of their time cleaning and preparing data. This so-called data wrangling is a crucial first step in organising data for subsequent analysis (NYTimes., 2014). The goal is generally to get the data into a “tidy” format whereby each variable is a column, each observation is a row and each value is a cell. The tidyverse package, developed by Hadley Wickham, is a collection of R packages built around this basic concept and intended to make data science fast, easy and fun. It contains six core packages: dplyr, tidyr, readr, purrr, ggplot2, and tibble. dplyr provides a useful selection of functions - each corresponding to a basic verb: dplyr function description select() Include or exclude certain variables (columns) arrange() Reorder observations (rows) filter() Include or exclude certain observations (rows) mutate() Create new variables (columns) and preserve existing ones group_by() Organise observations (rows) by variables (columns) summarise() Compute summary statistics for selected variables (columns) These are termed one table verbs as they only operate on one table at a time. Today we will focus on select(), arrange(), filter(), and mutate(). 3.2 Pre-Steps Before we can talk about today’s data, let’s do some house-keeping first. 3.2.1 Downloading materials Download the materials we will be working with today either from here or from moodle. The zip folder that contains an Rmd file called L3L4_stub, a data file called Student_Mental_Health.csv, a data file called Anx_Emp.csv and the paper “A Dataset of Students’ Mental Health and Help-Seeking Behaviors in a Multicultural Environment” (Nguyen et al., 2019). Similar to last week, L3L4_stub contains all code chunks for today’s lesson, and is intended for you to add notes and comments. 3.2.2 Unzipping the zip folder Make sure you unzip the folder and check it contains the L3L4_stub.Rmd, Student_Mental_Health.csv, and the Nguyen paper. 3.2.3 Setting the working directory Set that folder as your working directory for today. The files in the folders should now be visible in the Files pane. 3.2.4 Load tidyverse into the library As we will be using functions that are part of tidyverse, we need to load it into the library. library(tidyverse) 3.2.5 Reading in the data Today, we will be using the following data file Student_Mental_Health.csv. This contains demographic and mental health data for 268 students at an international university in Japan. The full version of this open access dataset and accompanying publication are available at https://www.mdpi.com/2306-5729/4/3/124. There is also a copy of this paper in today’s data folder. Now, you need to read the .csv file containing your data into your Global Environment using the function read_csv(). Remember to store your data in an appropriately named object (e.g. student_MH). student_MH &lt;- read_csv(&quot;Student_Mental_Health.csv&quot;) 3.2.6 View the data Either click on student_MH in your Global Environment to open your data in a new tab on the Source pane or call the object in your Console (by typing the name of the object student_MH) to check that the data was correctly imported into R. student_MH ## # A tibble: 268 x 19 ## ID inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Inter SEA Male Grad 24 Long Average ## 2 2 Inter SEA Male Grad 28 Short High ## 3 3 Inter SEA Male Grad 25 Long High ## 4 4 Inter EA Female Grad 29 Short Low ## 5 5 Inter EA Female Grad 28 Short Low ## 6 6 Inter SEA Male Grad 24 Long Average ## 7 7 Inter SA Male Grad 23 Short Average ## 8 8 Inter SEA Female Grad 30 Medium Low ## 9 9 Inter SEA Female Grad 25 Long High ## 10 10 Inter Others Male Grad 31 Medium Low ## # ... with 258 more rows, and 11 more variables: English_cate &lt;chr&gt;, ## # ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, APD &lt;dbl&gt;, AHome &lt;dbl&gt;, APH &lt;dbl&gt;, ## # Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; You could also view the data by using the function View(). If you are more of a typer than a mouse-user you can type View(student_MH) into your Console. This will open the data in a read-only, spreadsheet-like format in a new tab on the Source pane. Remember from last week, we can also use glimpse() to view the columns and their datatypes. glimpse(student_MH) ## Observations: 268 ## Variables: 19 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;In... ## $ Region &lt;chr&gt; &quot;SEA&quot;, &quot;SEA&quot;, &quot;SEA&quot;, &quot;EA&quot;, &quot;EA&quot;, &quot;SEA&quot;, &quot;SA&quot;, &quot;S... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Mal... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, ... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, ... ## $ Stay_Cate &lt;chr&gt; &quot;Long&quot;, &quot;Short&quot;, &quot;Long&quot;, &quot;Short&quot;, &quot;Short&quot;, &quot;Long... ## $ Japanese_cate &lt;chr&gt; &quot;Average&quot;, &quot;High&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Low&quot;, &quot;Averag... ## $ English_cate &lt;chr&gt; &quot;High&quot;, &quot;High&quot;, &quot;High&quot;, &quot;Average&quot;, &quot;Average&quot;, &quot;H... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95... head() would be helpful in displaying only the first 6 rows of the dataset, but remember not to get “tricked” by the number of observations shown in the output. head(student_MH) ## # A tibble: 6 x 19 ## ID inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Inter SEA Male Grad 24 Long Average ## 2 2 Inter SEA Male Grad 28 Short High ## 3 3 Inter SEA Male Grad 25 Long High ## 4 4 Inter EA Female Grad 29 Short Low ## 5 5 Inter EA Female Grad 28 Short Low ## 6 6 Inter SEA Male Grad 24 Long Average ## # ... with 11 more variables: English_cate &lt;chr&gt;, ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, ## # APD &lt;dbl&gt;, AHome &lt;dbl&gt;, APH &lt;dbl&gt;, Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, ## # AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; Question Time How many rows (or observations) does student_MH have? How many columns (or variables) does student_MH have? Take 10 minutes to read the data description section of the Nguyen publication in order to familiarise yourself with the variables in your dataframe. 3.3 Select() You may not want to include every single variable in your analysis. In order to include or exclude certain variables (columns), use the select() function. The first argument to this function is the object you want to select variables from (i.e. our tibble called student_MH), and the subsequent arguments are the variables to keep. For example, if you wanted to keep all variables except from ID, you could type: select(student_MH, inter_dom, Region, Gender, Academic, Age, Stay_Cate, Japanese_cate, English_cate, ToDep, ToSC, APD, AHome, APH, Afear, ACS, AGuilt, AMiscell, ToAS) ## # A tibble: 268 x 18 ## inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Inter SEA Male Grad 24 Long Average ## 2 Inter SEA Male Grad 28 Short High ## 3 Inter SEA Male Grad 25 Long High ## 4 Inter EA Female Grad 29 Short Low ## 5 Inter EA Female Grad 28 Short Low ## 6 Inter SEA Male Grad 24 Long Average ## 7 Inter SA Male Grad 23 Short Average ## 8 Inter SEA Female Grad 30 Medium Low ## 9 Inter SEA Female Grad 25 Long High ## 10 Inter Others Male Grad 31 Medium Low ## # ... with 258 more rows, and 11 more variables: English_cate &lt;chr&gt;, ## # ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, APD &lt;dbl&gt;, AHome &lt;dbl&gt;, APH &lt;dbl&gt;, ## # Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; Uuuuiiii. That was long and it would have taken us loads of time typing it out. There are two ways on how we could have done this easier and faster: We could use the colon operator :. Similar to last week where we used the colon operator for numerical sequences, we can use it here for selecting a sequence of column names. Here, it reads as “take object student_HM, and select columns inter_dom, ToAS, and everything in between”. select(student_MH, inter_dom:ToAS) ## # A tibble: 268 x 18 ## inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Inter SEA Male Grad 24 Long Average ## 2 Inter SEA Male Grad 28 Short High ## 3 Inter SEA Male Grad 25 Long High ## 4 Inter EA Female Grad 29 Short Low ## 5 Inter EA Female Grad 28 Short Low ## 6 Inter SEA Male Grad 24 Long Average ## 7 Inter SA Male Grad 23 Short Average ## 8 Inter SEA Female Grad 30 Medium Low ## 9 Inter SEA Female Grad 25 Long High ## 10 Inter Others Male Grad 31 Medium Low ## # ... with 258 more rows, and 11 more variables: English_cate &lt;chr&gt;, ## # ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, APD &lt;dbl&gt;, AHome &lt;dbl&gt;, APH &lt;dbl&gt;, ## # Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; We could use “negative selection”, i.e. select the variable we wanted to drop by adding a minus in front of it. select(student_MH, -ID) ## # A tibble: 268 x 18 ## inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Inter SEA Male Grad 24 Long Average ## 2 Inter SEA Male Grad 28 Short High ## 3 Inter SEA Male Grad 25 Long High ## 4 Inter EA Female Grad 29 Short Low ## 5 Inter EA Female Grad 28 Short Low ## 6 Inter SEA Male Grad 24 Long Average ## 7 Inter SA Male Grad 23 Short Average ## 8 Inter SEA Female Grad 30 Medium Low ## 9 Inter SEA Female Grad 25 Long High ## 10 Inter Others Male Grad 31 Medium Low ## # ... with 258 more rows, and 11 more variables: English_cate &lt;chr&gt;, ## # ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, APD &lt;dbl&gt;, AHome &lt;dbl&gt;, APH &lt;dbl&gt;, ## # Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; We also have the option of “de-selecting” more than one variable. Let’s say, we had no interest in any of the seven subscales for ToAS, we could exclude them by combining the colon operator : with the minus. Watch out that you include the minus in front of both reference columns. select(student_MH, -APD:-AMiscell) ## # A tibble: 268 x 12 ## ID inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Inter SEA Male Grad 24 Long Average ## 2 2 Inter SEA Male Grad 28 Short High ## 3 3 Inter SEA Male Grad 25 Long High ## 4 4 Inter EA Female Grad 29 Short Low ## 5 5 Inter EA Female Grad 28 Short Low ## 6 6 Inter SEA Male Grad 24 Long Average ## 7 7 Inter SA Male Grad 23 Short Average ## 8 8 Inter SEA Female Grad 30 Medium Low ## 9 9 Inter SEA Female Grad 25 Long High ## 10 10 Inter Others Male Grad 31 Medium Low ## # ... with 258 more rows, and 4 more variables: English_cate &lt;chr&gt;, ## # ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, ToAS &lt;dbl&gt; This only works, because they are all next to each other in the tibble. If we wanted to exclude columns ID, Academic, and ToAS that are not neighbouring each other, we would need to list the arguments separately, and insert a minus before each variable name. select(student_MH, -ID, -Academic, -ToAS) ## # A tibble: 268 x 16 ## inter_dom Region Gender Age Stay_Cate Japanese_cate English_cate ToDep ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Inter SEA Male 24 Long Average High 0 ## 2 Inter SEA Male 28 Short High High 2 ## 3 Inter SEA Male 25 Long High High 2 ## 4 Inter EA Female 29 Short Low Average 3 ## 5 Inter EA Female 28 Short Low Average 3 ## 6 Inter SEA Male 24 Long Average High 6 ## 7 Inter SA Male 23 Short Average High 3 ## 8 Inter SEA Female 30 Medium Low Low 9 ## 9 Inter SEA Female 25 Long High High 7 ## 10 Inter Others Male 31 Medium Low High 3 ## # ... with 258 more rows, and 8 more variables: ToSC &lt;dbl&gt;, APD &lt;dbl&gt;, ## # AHome &lt;dbl&gt;, APH &lt;dbl&gt;, Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, AGuilt &lt;dbl&gt;, ## # AMiscell &lt;dbl&gt; We can also use select() in combination with the c() function. Remember, c()is “hugging things together”. We would put a single minus in front of the c rather than each of the column. This will read as exclude every column listed within the brackets. select(student_MH, -c(ID, Academic, ToAS)) Remember, if you don’t save this data to an object (e.g. the original dataframe student_MH or under a new name), it won’t be saved. We have not saved any of the previous tasks to the Global Environment, so there should still be only one object, e.g. the tibble named student_MH. Question Time Your turn Create a tibble called short_MH that keeps all variables/columns from the data student_MH except from Region, Stay_Cate, Japanese_cate and English_cate. Your new object short_MH should appear in your Global Environment. Solution # Kate&#39;s solution: short_MH &lt;- select(student_MH, -Region, -Stay_Cate, -Japanese_cate, -English_cate) But there are plenty of other ways how this could have been done. For example: select(student_MH, ID, inter_dom, Gender, Academic, Age, ToDep, ToSC, APD, AHome, APH, Afear, ACS, AGuilt, AMiscell, ToAS) select(student_MH, ID, inter_dom, Gender:Age, ToDep:ToAS) select(student_MH, -c(Region, Stay_Cate, Japanese_cate, English_cate)) select(student_MH, -c(Region, Stay_Cate:English_cate)) select(student_MH, -Region, -Stay_Cate:-English_cate) This is mainly a matter of personal preference. You could also reference the position of column, rather than the actual name. select(student_MH,1,2,4:6,10:19) While it works code-wise, and seems a much quicker approach, it is a very bad idea in the name of reproducibility. If you send your code to a fellow researcher, they would have no idea what the code does. Moreover, if at some point, you need to add another column to your data, and/or decide to reorder the sequence of your columns, your code would not run anymore the way you expect it to. 3.4 Arrange() The arrange() function can reorder observations (rows) in ascending (default) or descending order. The first argument to this function is again an object (in this case the tibble short_MH we created in the previous section), and the subsequent arguments are the variables (columns) you want to sort by. For example, if you wanted to sort by Gender in ascending order (which is the default in arrange()) you would type: short_MH &lt;- arrange(short_MH, Gender) short_MH ## # A tibble: 268 x 15 ## ID inter_dom Gender Academic Age ToDep ToSC APD AHome APH ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 Inter Female Grad 29 3 37 16 10 10 ## 2 5 Inter Female Grad 28 3 37 15 12 5 ## 3 8 Inter Female Grad 30 9 41 16 20 19 ## 4 9 Inter Female Grad 25 7 36 22 12 13 ## 5 11 Inter Female Grad 28 5 32 24 8 10 ## 6 12 Inter Female Grad 31 8 47 17 12 14 ## 7 15 Inter Female Grad 31 9 31 23 16 15 ## 8 16 Inter Female Grad 30 6 40 19 9 5 ## 9 17 Inter Female Grad 31 3 48 11 13 7 ## 10 18 Inter Female Grad 29 3 48 16 4 5 ## # ... with 258 more rows, and 5 more variables: Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, ## # AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; Since you have assigned this code to the same object as before (i.e. short_MH), the previous version of short_MH is overwritten. Notice how the Gender column is now organised in alphabetical order i.e. females followed by males. Suppose you wanted to reverse this order, displaying males before females, you would need to wrap the name of the variable in the desc() function (i.e. for descending). short_MH &lt;- arrange(short_MH, desc(Gender)) short_MH ## # A tibble: 268 x 15 ## ID inter_dom Gender Academic Age ToDep ToSC APD AHome APH ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Inter Male Grad 24 0 34 23 9 11 ## 2 2 Inter Male Grad 28 2 48 8 7 5 ## 3 3 Inter Male Grad 25 2 41 13 4 7 ## 4 6 Inter Male Grad 24 6 38 18 8 10 ## 5 7 Inter Male Grad 23 3 46 17 6 10 ## 6 10 Inter Male Grad 31 3 48 8 4 5 ## 7 13 Inter Male Grad 29 1 48 8 11 5 ## 8 14 Inter Male Grad 23 3 32 9 8 5 ## 9 20 Inter Male Under 25 1 36 13 10 7 ## 10 21 Inter Male Under 18 4 26 18 4 7 ## # ... with 258 more rows, and 5 more variables: Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, ## # AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; You can also sort by more than one column. For example, you could sort by Gender and ToAS (total acculturative stress score) in ascending order: short_MH &lt;- arrange(short_MH, Gender, ToAS) glimpse(short_MH) ## Observations: 268 ## Variables: 15 ## $ ID &lt;dbl&gt; 45, 100, 101, 146, 206, 209, 241, 262, 187, 203, 248... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Dom&quot;, &quot;Dom&quot;, &quot;D... ## $ Gender &lt;chr&gt; &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;F... ## $ Academic &lt;chr&gt; &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;... ## $ Age &lt;dbl&gt; 20, 20, 20, 20, 21, 22, 21, 21, 22, 18, 22, 20, 21, ... ## $ ToDep &lt;dbl&gt; 6, 10, 3, 0, 10, 0, 4, 0, 6, 9, 7, 6, 6, 10, 7, 0, 9... ## $ ToSC &lt;dbl&gt; 48, 48, 48, 48, 48, 48, 48, 48, 44, 48, 48, 46, 40, ... ## $ APD &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 12, 8, 8, 8, 8,... ## $ AHome &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 9, 9, 7, 7... ## $ APH &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5... ## $ Afear &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5... ## $ ACS &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## $ AGuilt &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2... ## $ AMiscell &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 11, 11, 10, ... ## $ ToAS &lt;dbl&gt; 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 39, 40, ... Or descending order: short_MH &lt;- arrange(short_MH, desc(Gender), desc(ToAS)) glimpse(short_MH) ## Observations: 268 ## Variables: 15 ## $ ID &lt;dbl&gt; 188, 24, 231, 252, 142, 113, 62, 96, 190, 219, 23, 4... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Dom&quot;, &quot;Dom&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;I... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Mal... ## $ Academic &lt;chr&gt; &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;, &quot;Under&quot;... ## $ Age &lt;dbl&gt; 25, 20, 20, 23, 21, 19, 18, 23, 25, 21, 19, 18, 23, ... ## $ ToDep &lt;dbl&gt; 13, 1, 14, 13, 9, 2, 2, 21, 9, 11, 13, 12, 7, 0, 9, ... ## $ ToSC &lt;dbl&gt; 17, 34, 24, 32, 24, 40, 40, 21, 39, 24, 25, 39, 28, ... ## $ APD &lt;dbl&gt; 35, 24, 28, 24, 24, 24, 24, 32, 19, 27, 25, 18, 26, ... ## $ AHome &lt;dbl&gt; 16, 16, 15, 12, 12, 12, 13, 16, 16, 8, 16, 20, 7, 9,... ## $ APH &lt;dbl&gt; 21, 15, 13, 16, 15, 15, 25, 20, 13, 14, 10, 10, 11, ... ## $ Afear &lt;dbl&gt; 13, 12, 11, 12, 12, 12, 10, 12, 8, 12, 11, 8, 8, 8, ... ## $ ACS &lt;dbl&gt; 11, 11, 10, 9, 9, 6, 6, 6, 12, 10, 6, 6, 8, 11, 9, 4... ## $ AGuilt &lt;dbl&gt; 4, 8, 6, 6, 6, 6, 6, 2, 8, 4, 4, 9, 2, 2, 2, 4, 3, 4... ## $ AMiscell &lt;dbl&gt; 29, 37, 29, 30, 30, 30, 20, 13, 25, 21, 22, 23, 30, ... ## $ ToAS &lt;dbl&gt; 129, 123, 112, 109, 108, 105, 104, 101, 101, 96, 94,... Question Time Your turn Hmmm, I wish we hadn’t overwritten our original data short_MH repeatedly. Arrange the rows back to the way they were (i.e. sort by ID). Solution short_MH &lt;- arrange(short_MH, ID) 3.5 Filter() 3.5.1 Single criterion In order to include or exclude certain observations (rows), use the filter() function. The first argument to this function is an object (in this case the tibble short_MH we created earlier) and the subsequent argument is the criteria you wish to filter on. For example, if you want only those observations with total acculturative stress scores of more than 72: short_MH72 &lt;- filter(short_MH, ToAS &gt; 72) glimpse(short_MH72) ## Observations: 131 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 4, 5, 6, 8, 9, 11, 12, 15, 16, 23, 24, 25, 27, 28... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Femal... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 29, 28, 24, 30, 25, 28, 31, 31, 30, 19, 20, 29, ... ## $ ToDep &lt;dbl&gt; 0, 3, 3, 6, 9, 7, 5, 8, 9, 6, 13, 1, 8, 13, 9, 9, 9,... ## $ ToSC &lt;dbl&gt; 34, 37, 37, 38, 41, 36, 32, 47, 31, 40, 25, 34, 39, ... ## $ APD &lt;dbl&gt; 23, 16, 15, 18, 16, 22, 24, 17, 23, 19, 25, 24, 18, ... ## $ AHome &lt;dbl&gt; 9, 10, 12, 8, 20, 12, 8, 12, 16, 9, 16, 16, 8, 15, 9... ## $ APH &lt;dbl&gt; 11, 10, 5, 10, 19, 13, 10, 14, 15, 5, 10, 15, 10, 11... ## $ Afear &lt;dbl&gt; 8, 8, 8, 8, 15, 13, 8, 13, 8, 4, 11, 12, 8, 9, 11, 8... ## $ ACS &lt;dbl&gt; 11, 6, 7, 7, 11, 10, 6, 9, 12, 13, 6, 11, 7, 5, 7, 6... ## $ AGuilt &lt;dbl&gt; 2, 4, 4, 3, 6, 6, 6, 4, 8, 2, 4, 8, 4, 2, 6, 4, 4, 8... ## $ AMiscell &lt;dbl&gt; 27, 21, 31, 29, 40, 33, 30, 26, 30, 22, 22, 37, 23, ... ## $ ToAS &lt;dbl&gt; 91, 75, 82, 83, 127, 109, 92, 95, 112, 74, 94, 123, ... Since the column ToAS has numeric values with no decimal places, we could have coded this as filter(short_MH, ToAS &gt;= 73). Don’t believe it? Try it out in your Console. Notice how we saved the new data under a different object name (short_MH72). When using filter(), you should never replace/ overwrite your original data unless you know exactly what you are doing. What could be the consequences? By the way, what do symbols such &gt; and &gt;= remind you of??? (hint: something we covered last week?) Answers Consequences: You could potentially lose some data. Nothing is ever completely lost though (unless you are overwriting the original .csv file) but it could result in more work for you to restore everything from the beginning. Especially when your data scripts are very long and analysis is complex (i.e. taking up a lot of computing power), that could easily turn into a nightmare. Remember the relational operators that returned logical values of either TRUE or FALSE? Relational operators (such as ==, !=, &lt;, &lt;=, &gt;, and &gt;=) compare two numerical expressions and return a Boolean variable: a variable whose value is either 0 (FALSE) or 1 (TRUE). So, essentially, filter() includes any observations (rows) for which the expression evaluates to TRUE, and excludes any for which it evaluates to FALSE. In the previous example, filter() sifted through 268 observations, keeping rows containing total acculturative stress scores more than 72 and rejecting those with scores less than or equal to 72. This works as well for columns of the data type character. If you want only those observations for international students (as opposed to domestic students), you could use the equivalence operator ==. Be aware that a single equals sign (=) is used to assign a value to a variable whereas a double equals sign (==) is used to check whether two values are equal. short_MH_inter &lt;- filter(short_MH, inter_dom == &quot;Inter&quot;) Here, the filter() function compares every single value in the column inter_dom of the data object short_HM with the character string written on the right-hand side of the equation (“Inter”). Another way to produce the exact same outcome, would be to exclude domestic students using the ‘not equals’ operator !=. Here filter() keeps every row in which the value does not read “Dom”. short_MH_inter2 &lt;- filter(short_MH, inter_dom != &quot;Dom&quot;) You can view short_MH_inter and short_MH_inter2 in a tab, use glimpse(), or call the variable in the Console to check that are actually identical. glimpse(short_MH_inter) ## Observations: 201 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... glimpse(short_MH_inter2) ## Observations: 201 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... 3.5.2 Multiple criteria More often than not, you will need to filter based on multiple criteria. For that you have the options of AND and OR. ANDis used if you had two criteria and only wanted data returned when both criteria are met. ORis used if you had two criteria and wanted data returned for either criterion. Simple Example: Just imagine, you have data of men and women who are either blond or dark-haired. If you wanted to filter everyone who has blond hair AND is a man, all your data looks like this: Whereas, if you wanted to filter out everyone who has either dark hair OR is a woman, you would get: What does that mean for our student mental health data? For example, to filter rows containing only international students who have a total acculturative stress score of more than 72, you would code: short_MH72_inter &lt;- filter(short_MH, inter_dom == &quot;Inter&quot;, ToAS &gt; 72) glimpse(short_MH72_inter) ## Observations: 109 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 4, 5, 6, 8, 9, 11, 12, 15, 16, 23, 24, 25, 27, 28... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Femal... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 29, 28, 24, 30, 25, 28, 31, 31, 30, 19, 20, 29, ... ## $ ToDep &lt;dbl&gt; 0, 3, 3, 6, 9, 7, 5, 8, 9, 6, 13, 1, 8, 13, 9, 9, 9,... ## $ ToSC &lt;dbl&gt; 34, 37, 37, 38, 41, 36, 32, 47, 31, 40, 25, 34, 39, ... ## $ APD &lt;dbl&gt; 23, 16, 15, 18, 16, 22, 24, 17, 23, 19, 25, 24, 18, ... ## $ AHome &lt;dbl&gt; 9, 10, 12, 8, 20, 12, 8, 12, 16, 9, 16, 16, 8, 15, 9... ## $ APH &lt;dbl&gt; 11, 10, 5, 10, 19, 13, 10, 14, 15, 5, 10, 15, 10, 11... ## $ Afear &lt;dbl&gt; 8, 8, 8, 8, 15, 13, 8, 13, 8, 4, 11, 12, 8, 9, 11, 8... ## $ ACS &lt;dbl&gt; 11, 6, 7, 7, 11, 10, 6, 9, 12, 13, 6, 11, 7, 5, 7, 6... ## $ AGuilt &lt;dbl&gt; 2, 4, 4, 3, 6, 6, 6, 4, 8, 2, 4, 8, 4, 2, 6, 4, 4, 8... ## $ AMiscell &lt;dbl&gt; 27, 21, 31, 29, 40, 33, 30, 26, 30, 22, 22, 37, 23, ... ## $ ToAS &lt;dbl&gt; 91, 75, 82, 83, 127, 109, 92, 95, 112, 74, 94, 123, ... You could have also used the logical operator &amp; (AND) instead of the comma. filter(short_MH, inter_dom == “Inter” &amp; ToAS &gt; 72) would have given you the same result as above. If we wanted to filter the data short_MH for either international students OR students with total acculturative stress scores of more than 72, we could use the logical operator | (OR). short_MH72_inter_or &lt;- filter(short_MH, inter_dom == &quot;Inter&quot; | ToAS &gt; 72) glimpse(short_MH72_inter_or) ## Observations: 223 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... As you will have noticed, short_MH72_inter_or has now observations for participants that are either international students, or students with a ToAS of larger than 72. Undoubtedly, some will fall into both categories, however, participants that fit neither criterion are excluded. Question Time How many rows (or observations) does the object short_MH72 contain? How many participants in this study were international students? How many observations would the code filter(short_MH, inter_dom == \"inter\") return? How many participants in this study were international students with a ToAS of more than 72? How many participants in this study were either international students OR had a ToAS of more than 72? 3.6 Mutate() The mutate() function creates new variables (columns) onto the existing object. The first argument to this function is an object from your Global Environment (for example short_MH we created earlier) and the subsequent argument is the new column name and what you want it to contain. The following image was downloaded from https://www.sharpsightlabs.com/blog/mutate-in-r/ Let’s apply this to this to our short_MH data tibble. Say we wanted to create a new column Age_double that shows us the age of our participants if they are twice as old as they are now. We will save this as a new object short_MH_ext to our Global Environment rather than overwriting short_MH so that we can compare short_MH with the extended short_MH_ext later on. short_MH_ext &lt;- mutate(short_MH, Age_double = Age*2) glimpse(short_MH_ext) ## Observations: 268 ## Variables: 16 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48,... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16,... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 1... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17,... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 5... ## $ Age_double &lt;dbl&gt; 48, 56, 50, 58, 56, 48, 46, 60, 50, 62, 56, 62, 58,... As we can see, short_MH_ext has one column more than short_MH. So mutate() took the value in the cells for each row of the variable Age, mutiplied it by 2, and added it to the new column Age_double. Importantly, new variables will overwrite existing variables if column headings are identical. So if we wanted to halve the values in column Age_double and store them in a column Age_double, the original Age_double would be overwritten. short_MH_ext &lt;- mutate(short_MH_ext, Age_double = Age_double/2) glimpse(short_MH_ext) ## Observations: 268 ## Variables: 16 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48,... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16,... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 1... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17,... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 5... ## $ Age_double &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... So now, short_MH_ext did not gain a column (it still contains 16 variables), and Age_double has now the same values as column Age. The main take-away message here is to always check your data after manipulation if the outcome is really what you would expected. If you don’t inspect and acidentally overwrite columns, you would not notice any difference. No need to keep column Age_double anymore; we could just drop it. And we are back to 15 variable columns. short_MH_ext &lt;- mutate(short_MH_ext, Age_double = NULL) glimpse(short_MH_ext) ## Observations: 268 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... If you want to add more than 2 columns, you can do that in a single mutate() statement. You can also add variables that are not numerical values, such as character or logical. Let’s have a look at the column ToDep. According to the PHQ, the maximum score for that measure is 27, and patients having a score of 20 or above count as severely depressed. More information can be found on https://www.ncor.org.uk/wp-content/uploads/2012/12/Patient-Health-Questionnaire.pdf Say we wanted to add two columns to short_MH_ext. Column 1 is called max_PHQ and contains the maximum score of 27 that can be achieved in the Patient Health Questionnaire Column 2 is called Dep_Severe and is of datatype logical. It contains a comparison of the value in ToDep with the cut off score of 20. Values 20 and above should read TRUE, all other values FALSE. short_MH_ext &lt;- mutate(short_MH_ext, max_PHQ = 27, Dep_Severe = ToDep &gt;= 20) glimpse(short_MH_ext) ## Observations: 268 ## Variables: 17 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48,... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16,... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 1... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17,... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 5... ## $ max_PHQ &lt;dbl&gt; 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,... ## $ Dep_Severe &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA... For column max_PHQ, we would not have to repeat the number 27 268 times. As it’s the same number for all cells, mentioning it once sets all the values in the column to that particular number (similar to “Scotland” last week when we were creating tibbles). Dep_Severe = ToDep &gt;= 20 might look a bit alien to you, but remember that a single equals sign (=) is used to assign a value to a variable whereas the relational operator (&gt;=) is used to check whether two values are equal. These can actually co-exist in one statement. Here R reads the expression as: \"compare for each row whether the cell value in ToDep is equal or larger than 20. If yes, put TRUE in the new column Dep_Severe; if not, put FALSE. There are 8 students in this data set who would categorise as severely depressed. Your turn Add a new column to short_MH_ext that is called Total_Score that adds together the seven subscales for each observation (row). *Hint: APD + AHome + … + AMiscell would do the trick. If we have done it correctly, Total_Score should have the same values as ToAS. Add a second new column that is called correct that evaluates whether Total_Score and ToAS are identical columns. Solution short_MH_ext &lt;- mutate(short_MH_ext, Total_Score = APD + AHome + APH + Afear + ACS + AGuilt + AMiscell, Correct = Total_Score == ToAS) glimpse(short_MH_ext) ## Observations: 268 ## Variables: 19 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inte... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;G... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3,... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, ... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 1... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5,... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, ... ## $ max_PHQ &lt;dbl&gt; 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27... ## $ Dep_Severe &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F... ## $ Total_Score &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, ... ## $ Correct &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR... Follow-up Question Although the last examples are useful to illustrate how mutate() works, you do not need two identical columns. Using one of today’s dplyr functions, remove the columns Total_Score and Correct from the dataset short_MH_ext. Save this as a new object short_MH_ext2 to your Global Environment. Solution short_MH_ext2 &lt;- mutate(short_MH_ext, Total_Score = NULL, Correct = NULL) glimpse(short_MH_ext2) ## Observations: 268 ## Variables: 17 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48,... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16,... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 1... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17,... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 5... ## $ max_PHQ &lt;dbl&gt; 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,... ## $ Dep_Severe &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA... You could have also used the function select() to drop or select variable columns. For example: select(short_MH_ext, ID:Dep_Severe) or select(short_MH_ext, -Total_Score, -Correct) 3.7 Formative Homework 3.7.1 Brief introduction to the homework data For the homework assignments each week, we will be using an open access dataset into how personality is determined from voices. A full version of the paper can be found https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0204991. All data and sounds are available on OSF (osf.io/s3cxy). However, for your assignment this week, all files necessary are compiled in a folder to download from moodle. The data in the TraitJudgementData.csv has ratings on 3 different personality traits (Trustworthiness, Dominance, and Attractiveness) for 30 male and 30 female voice stimuli. In total, 181 participants rated either male OR female speakers on ONE personality trait (e.g. Trustworthiness) only. The speakers were judged after saying a socially relevant word (“Hello”), a socially ambiguous word (“Colors”), a socially relevant sentence (“I urge you to submit your essay by the end of the week”), and a socially ambiguous sentence (“Some have accepted it as a miracle without physical explanation”). Socially relevant stimuli were meant to address the listener, whereas socially ambiguous stimuli were intended to not be directed towards the listener. Each participant rated all the voice stimuli twice in all four conditions (socially relevant words (RW), socially relevant sentences (RS), socially ambiguous words (AW), and socially ambiguous sentences (AS)). The experiment was conducted online. Here is a brief summary overview of the columns in the TraitJudgementData.csv. column name description PP_ID Participant’s ID PP_Age Participant’s Age PP_Sex Participant’s Sex (“female”, “male”) Nationality Participant’s Nationality Trait Personality Trait participant judged the vocal stimuli on (“Trustworthiness”, “Dominance”, “Attractiveness”) Voice Speaker’s ID Voice_Sex Speaker’s Sex (“Female”, “Male”) Condition Speaker’s recording of socially relevant words (RW), socially relevant sentences (RS), socially ambiguous words (AW), and socially ambiguous sentences (AS) Rating Participants rated each Voice in each Condition twice - (“Rating1”, “Rating2”) Response Participant’s Trait judgements on a scale from 1 - 500 Reaction Participant’s Reaction Time "],
["data-transformation-2-two-table-verbs.html", "Chapter 4 Data Transformation 2: Two Table Verbs Intended Learning Outcomes 4.1 Pre-Steps 4.2 Group_by() and Summarise() 4.3 The pipe operator (%&gt;%) 4.4 Two-Table Verbs 4.5 Additional information 4.6 Summative Homework", " Chapter 4 Data Transformation 2: Two Table Verbs Intended Learning Outcomes Be able to use the following dplyr one-table verbs: group_by() summarise() Be able to chain functions together using the pipe operator (%&gt;%) Be able to use the following dplyr two-table verbs: Mutating joins: left_join(), right_join(), full_join(), inner_join() Binding joins: bind_rows(), bind_cols() First, we will cover the remaining ‘one-table verbs’ - group_by() and summarise() - and introduce the pipe operator. 4.1 Pre-Steps Set your working directory to the L3L4_data folder we were working with last week and that contains the data files Student_Mental_Health.csv and Anx_Emp.csv. Open the L3L4_stub file. Load tidyverse into the library. Read the data from Student_Mental_Health.csv into your Global Environment as student_MH. Deselect the columns Region, Stay_Cate, Japanese_cate, and English_cate. Store this data as an object short_MH. Read the data from Anx_Emp.csv into your Global Environment as extra_MH. This data will be needed for the two-table verbs later on. Anx_Emp.csv contains fake data relating to 267 students in the previous data file (short_MH). The column GAD7 refers to students’ scores on the Generalized Anxiety Disorder 7-item (GAD-7) questionnaire and the column Employment outlines the students’ employment status i.e. part-time, full-time or unemployed. Solution library(tidyverse) student_MH &lt;- read_csv(&quot;Student_Mental_Health.csv&quot;) short_MH &lt;- select(student_MH, -Region, -Stay_Cate, -Japanese_cate, -English_cate) extra_MH &lt;- read_csv(&quot;Anx_Emp.csv&quot;) 4.2 Group_by() and Summarise() In order to compute summary statistics such as mean, median and standard deviation, use the summarise() function. The first argument to this function is the object short_MH and the subsequent argument is the new column name and what mathematical operation you want it to contain. You can add as many summary statistics in one summarise() function as you want; just separate them by a comma. For example, say you wanted to work out the mean total score of depression and accompanying standard deviation for the entire sample: short_MH_ToDep &lt;- summarise(short_MH, mean = mean(ToDep), sd = sd(ToDep)) short_MH_ToDep ## # A tibble: 1 x 2 ## mean sd ## &lt;dbl&gt; &lt;dbl&gt; ## 1 8.19 4.95 Therefore, the mean total score of depression is 8.19 with a standard deviation of 4.95. It would be interesting to break these summary statistics down by Gender. This is where the group_by() function comes in handy. It can organise observations (rows) by variables (columns) such as Gender. The first argument to this function is the object you created last week (short_MH) and the subsequent argument is the variable you want to group by: short_MH_gen &lt;- group_by(short_MH, Gender) If you view the object short_MH_gen, it will not look any different to the original dataset (short_MH). However, be aware that the underlying structure has changed. In fact, you could type glimpse(short_MH_gen) to double check this. glimpse(short_MH_gen) ## Observations: 268 ## Variables: 15 ## Groups: Gender [2] ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... You can now feed this grouped dataset (short_MH_gen) into the previous code line to obtain summary statistics by Gender: short_MH_ToDep_gen &lt;- summarise(short_MH_gen, mean = mean(ToDep), sd = sd(ToDep)) short_MH_ToDep_gen ## # A tibble: 2 x 3 ## Gender mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Female 8.4 4.67 ## 2 Male 7.82 5.42 Question Time What gender has the highest mean total score of depression? You might also want to calculate and display the number of males and females in the dataset. This can be achieved by adding the summary function n() to your previous code line: short_MH_ToDep_gen &lt;- summarise(short_MH_gen, n = n(), mean = mean(ToDep), sd = sd(ToDep)) short_MH_ToDep_gen ## # A tibble: 2 x 4 ## Gender n mean sd ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Female 170 8.4 4.67 ## 2 Male 98 7.82 5.42 Question Time How many males are in the dataset? How many females are in the dataset? Finally, it is possible to add multiple grouping variables. For example, the following code groups short_MH by Gender and Academic level and then calculates the mean total score of depression (ToDep) for males and females at each academic level. short_MH_group &lt;- group_by(short_MH, Gender, Academic) short_MH_ToDep_group &lt;- summarise(short_MH_group, mean = mean(ToDep)) short_MH_ToDep_group ## # A tibble: 4 x 3 ## # Groups: Gender [2] ## Gender Academic mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Female Grad 7 ## 2 Female Under 8.52 ## 3 Male Grad 2.5 ## 4 Male Under 8.29 Question Time Which group appears to be most resilient to depression? female undergraduates male undergraduates female graduates male graduates Luckily for you, the dataset does not contain any missing values, denoted NA in R. Missing values are always a bit of a hassle to deal with. Any computation you do that involves NA returns an NA - which translates as “you will not get a numeric result when your column contains missing values”. Missing values can be removed by adding the argument na.rm = TRUE to calculation functions like mean(), median() or sd(). For example, the previous code line would read: short_MH_ToDep_group &lt;- summarise(short_MH_group, mean = mean(ToDep, na.rm = TRUE)) If you need to return the data to a non-grouped form, use the ungroup() function. glimpse(short_MH_gen) ## Observations: 268 ## Variables: 15 ## Groups: Gender [2] ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... short_MH_gen &lt;- ungroup(short_MH_gen) glimpse(short_MH_gen) ## Observations: 268 ## Variables: 15 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, ... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gra... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, ... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, ... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, ... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, ... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, ... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13,... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, ... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54... 4.3 The pipe operator (%&gt;%) As you may have noticed, your environment pane has become increasingly cluttered. Indeed, every time you introduced a new line of code, you created a uniquely-named object (unless your original object is overwritten). This can become confusing and time-consuming. One solution is the pipe operator (%&gt;%) which aims to increase efficiency and improve the readability of your code. The pipe operator (%&gt;%) read as “and then” and allows you to chain functions together, eliminating the need to create intermediary objects. There is no limit as to how many functions you can chain together in a single pipeline. For example, in order to select(), arrange(), group_by() and summarise() the data, you used the following code lines: short_MH &lt;- select(student_MH, -Region, -Stay_Cate, -Japanese_cate, -English_cate) short_MH_arr &lt;- arrange(short_MH, desc(Gender), desc(ToAS)) short_MH_group &lt;- group_by(short_MH_arr, Gender, Academic) short_MH_ToDep_group &lt;- summarise(short_MH_group, mean = mean(ToDep)) short_MH_ToDep_group ## # A tibble: 4 x 3 ## # Groups: Gender [2] ## Gender Academic mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Female Grad 7 ## 2 Female Under 8.52 ## 3 Male Grad 2.5 ## 4 Male Under 8.29 However, utilisation of the pipe operator (%&gt;%) can simplify this process and create only one object (short_MH_ToDep_group2) as shown: short_MH_ToDep_group2 &lt;- student_MH %&gt;% select(-Region, -Stay_Cate, -Japanese_cate, -English_cate) %&gt;% arrange(desc(Gender), desc(ToAS)) %&gt;% group_by(Gender, Academic) %&gt;% summarise(mean = mean(ToDep)) short_MH_ToDep_group2 ## # A tibble: 4 x 3 ## # Groups: Gender [2] ## Gender Academic mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Female Grad 7 ## 2 Female Under 8.52 ## 3 Male Grad 2.5 ## 4 Male Under 8.29 As you can see, short_MH_ToDep_group2 produces the same output as short_MH_ToDep_group. So, pipes automatically take the output from one function and feed it directly to the next function. Without pipes, you needed to insert your chosen dataset as the first argument to every function. With pipes, you are only required to specify the original dataset (i.e student_MH) once at the beginning and the pipes will do the rest. Note that in the above code chunk, the data object has been on its own line in the code followed immediately by %&gt;% before starting with the “functions”. short_MH_ToDep_group2 &lt;- student_MH %&gt;% select(-Region, -Stay_Cate, -Japanese_cate, -English_cate) %&gt;% … The other option would have been to put the data object as the first argument within the first function, such as short_MH_ToDep_group2 &lt;- select(student_MH, -Region, -Stay_Cate, -Japanese_cate, -English_cate) %&gt;% … The benefit of having the data on its own is that you reorder functions easily or squeeze another one in (for example if you summarised something but forgot to group beforehand) without having to remember to “move” the data object into the first argument of the chain. 4.4 Two-Table Verbs More often than not, data scientists collect and store their data across multiple tables. In order to effectively combine multiple tables, dplyr provides a selection of two-table verbs. Today we will focus on two categories of two-table verbs - mutating join verbs and binding join verbs. 4.4.1 Mutating Join Verbs Mutating join verbs combine the variables (columns) of two tables so that matching rows are together. There are 4 different types of mutating joins, namely inner_join(), left_join(), right_join(), and full_join(). Mutating joins have the following basic syntax: Let’s investigate joins using a simple example by creating two tibbles, data1 (shown below in blue) and data2 (shown below in green), both with only two columns, and two rows. Coded in R that would look like: data1 &lt;- tibble(ID = 1:2, X1 = c(&quot;a1&quot;, &quot;a2&quot;)) data2 &lt;- tibble(ID = 2:3, X2 = c(&quot;b1&quot;, &quot;b2&quot;)) 4.4.1.1 inner_join() An inner join returns all rows from x that have a match in y, whereby x is the first (left) table and y is the second (right) table. All columns from x and y are present in the merged object. If there are multiple rows that match, all of them are returned. Merging data1 and data2 by inner_join() would be coded in R: inner_join(data1, data2, by=&quot;ID&quot;) ## # A tibble: 1 x 3 ## ID X1 X2 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 a2 b1 Using an inner join would return only 1 row of observations because the only ID value matching in data1 and data2 is the row with ID = 2. However, we are still merging both tibbles together, meaning that all columns from data1 and data2 are kept (in our case X1 and X2). inner_join(data1, data2) would have produced the same outcome. When the by statement is omitted, data1 and data2 are joined by ALL “overlapping” variable columns (in this case ID). Don’t believe it? Try it out in your Console! Question Time Let’s apply an inner join to join short_MH with extra_MH (the fake data we read in during today’s pre-steps). Before we do that, it might be wise to remind ourselves of the number of rows and columns we are dealing with in both datasets. How many rows (or observations) does short_MH have? How many columns (or variables) does short_MH have? How many rows (or observations) does extra_MH have? How many columns (or variables) does extra_MH have? Notice that: Both datasets contain a common column ID One person (ID = 3) is missing from the second dataset (extra_MH) Your turn Now join short_MH and extra_MH using inner_join(). Save your results in the Global Environment as an object called MH_inner. How many rows and columns do you think MH_inner should have? Solution MH_inner &lt;- inner_join(short_MH, extra_MH, by = &quot;ID&quot;) glimpse(MH_inner) ## Observations: 267 ## Variables: 17 ## $ ID &lt;dbl&gt; 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, 23,... ## $ ToDep &lt;dbl&gt; 0, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, 32,... ## $ APD &lt;dbl&gt; 23, 8, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, 23,... ## $ AHome &lt;dbl&gt; 9, 7, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, 9,... ## $ APH &lt;dbl&gt; 11, 5, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15, ... ## $ Afear &lt;dbl&gt; 8, 4, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13, 8... ## $ AGuilt &lt;dbl&gt; 2, 2, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, 18,... ## $ ToAS &lt;dbl&gt; 91, 39, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54, 5... ## $ GAD7 &lt;dbl&gt; 8, 1, 0, 1, 14, 2, 1, 0, 2, 0, 2, 8, 0, 6, 12, 4, 0... ## $ Employment &lt;chr&gt; &quot;Unemployed&quot;, &quot;Part&quot;, &quot;Part&quot;, &quot;Full&quot;, &quot;Unemployed&quot;,... MH_inner has 267 rows, and 17 columns. rows: The overlapping ID numbers in both dataframes are 1,2,4,5…,268 which makes for 267 values. columns: total number of columns is 15 (from short_MH) + 3 (from extra_MH) - the column ID that exists in both objects. Notice how no rows have missing values. 4.4.1.2 left_join() A left join returns all rows from x, and all columns from x and y. Rows in the left table with no match in the right table will have missing values (NA) in the new columns. Let’s try this left_join() function for our simple example of data1 and data2 in R. left_join(data1, data2, by=&quot;ID&quot;) ## # A tibble: 2 x 3 ## ID X1 X2 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 b1 Here data1 is returned in full, and for every matching ID number, the value from data2 is added for X2. However, data2 does not have any value for ID = 1, hence NA is added in X2. Question Time Your turn Combine short_MH and extra_MH using left_join(). Save your results in the Global Environment as an object called MH_left. How many rows and columns are you expecting for MH_left? Solution MH_left &lt;- left_join(short_MH, extra_MH, by = &quot;ID&quot;) glimpse(MH_left) ## Observations: 268 ## Variables: 17 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48,... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16,... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 1... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17,... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 5... ## $ GAD7 &lt;dbl&gt; 8, 1, NA, 0, 1, 14, 2, 1, 0, 2, 0, 2, 8, 0, 6, 12, ... ## $ Employment &lt;chr&gt; &quot;Unemployed&quot;, &quot;Part&quot;, NA, &quot;Part&quot;, &quot;Full&quot;, &quot;Unemploy... Remember that ID number 3 is missing from the second (right) dataset. Since the first (left) dataset is prioritised in a left_join() and data1 contains ID number 3, it is retained in the new dataset MH_left and NA is added to GAD7 and Employment. 4.4.1.3 right_join() A right join returns all rows from y, and all columns from x and y, whereby y is the second (right table) and x is the first (left) table. Rows in the second table with no match in the first table will have NA values in the new columns. However, code-wise, you would still enter x as the first, and y as the second argument within right_join(). right_join(data1, data2, by = &quot;ID&quot;) ## # A tibble: 2 x 3 ## ID X1 X2 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 a2 b1 ## 2 3 &lt;NA&gt; b2 Here data2 is returned in full, and for every matching ID number, the value from data1 is added for X1. As data1 does not have any value for ID = 3, NA is added in column X1 . Notice the order of the columns, though!!! ID, X1 and X2. That is due to the order of how they are entered into the right_join() function. Question Time Your turn combine short_MH and extra_MH using right_join(). Save your results in the Global Environment as an object called MH_right. How many rows and columns should MH_right have? Solution MH_right &lt;- right_join(short_MH, extra_MH, by = &quot;ID&quot;) glimpse(MH_right) ## Observations: 267 ## Variables: 17 ## $ ID &lt;dbl&gt; 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29, 23,... ## $ ToDep &lt;dbl&gt; 0, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48, 32,... ## $ APD &lt;dbl&gt; 23, 8, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9, 23,... ## $ AHome &lt;dbl&gt; 9, 7, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16, 9,... ## $ APH &lt;dbl&gt; 11, 5, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 15, ... ## $ Afear &lt;dbl&gt; 8, 4, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13, 8... ## $ AGuilt &lt;dbl&gt; 2, 2, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, 2, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17, 18,... ## $ ToAS &lt;dbl&gt; 91, 39, 75, 82, 83, 58, 127, 109, 51, 92, 95, 54, 5... ## $ GAD7 &lt;dbl&gt; 8, 1, 0, 1, 14, 2, 1, 0, 2, 0, 2, 8, 0, 6, 12, 4, 0... ## $ Employment &lt;chr&gt; &quot;Unemployed&quot;, &quot;Part&quot;, &quot;Part&quot;, &quot;Full&quot;, &quot;Unemployed&quot;,... We should receive 267 observations and 17 columns. Since the second (right) table is prioritised and does not contain ID number 3, it is absent from the new dataset. In this case, right_join() produces the same output as inner_join(). 4.4.1.4 full_join() A full join returns all rows and all columns from both x and y, whereby x is the first (left) table and y is the second (right) table. NA values fill unmatched rows. full_join(data1, data2) ## Joining, by = &quot;ID&quot; ## # A tibble: 3 x 3 ## ID X1 X2 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 b1 ## 3 3 &lt;NA&gt; b2 As you can see, ID values (1,2, and 3) from both dataframes are retained. ID = 3 does not exist in data1, and ID = 1 does not exist in data2, X1 and X2 are filled with NA respectively. Question Time Your turn combine short_MH and extra_MH using full_join(). Save your results in the Global Environment as an object called MH_full. How many rows and columns are you expecting for MH_right? Solution MH_full &lt;- full_join(short_MH, extra_MH, by = &quot;ID&quot;) glimpse(MH_full) ## Observations: 268 ## Variables: 17 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ... ## $ inter_dom &lt;chr&gt; &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter&quot;, &quot;Inter... ## $ Gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;,... ## $ Academic &lt;chr&gt; &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Grad&quot;, &quot;Gr... ## $ Age &lt;dbl&gt; 24, 28, 25, 29, 28, 24, 23, 30, 25, 31, 28, 31, 29,... ## $ ToDep &lt;dbl&gt; 0, 2, 2, 3, 3, 6, 3, 9, 7, 3, 5, 8, 1, 3, 9, 6, 3, ... ## $ ToSC &lt;dbl&gt; 34, 48, 41, 37, 37, 38, 46, 41, 36, 48, 32, 47, 48,... ## $ APD &lt;dbl&gt; 23, 8, 13, 16, 15, 18, 17, 16, 22, 8, 24, 17, 8, 9,... ## $ AHome &lt;dbl&gt; 9, 7, 4, 10, 12, 8, 6, 20, 12, 4, 8, 12, 11, 8, 16,... ## $ APH &lt;dbl&gt; 11, 5, 7, 10, 5, 10, 10, 19, 13, 5, 10, 14, 5, 5, 1... ## $ Afear &lt;dbl&gt; 8, 4, 6, 8, 8, 8, 5, 15, 13, 12, 8, 13, 4, 4, 8, 4,... ## $ ACS &lt;dbl&gt; 11, 3, 4, 6, 7, 7, 3, 11, 10, 3, 6, 9, 7, 6, 12, 13... ## $ AGuilt &lt;dbl&gt; 2, 2, 3, 4, 4, 3, 2, 6, 6, 2, 6, 4, 2, 7, 8, 2, 5, ... ## $ AMiscell &lt;dbl&gt; 27, 10, 14, 21, 31, 29, 15, 40, 33, 17, 30, 26, 17,... ## $ ToAS &lt;dbl&gt; 91, 39, 51, 75, 82, 83, 58, 127, 109, 51, 92, 95, 5... ## $ GAD7 &lt;dbl&gt; 8, 1, NA, 0, 1, 14, 2, 1, 0, 2, 0, 2, 8, 0, 6, 12, ... ## $ Employment &lt;chr&gt; &quot;Unemployed&quot;, &quot;Part&quot;, NA, &quot;Part&quot;, &quot;Full&quot;, &quot;Unemploy... We should receive 268 observations and 17 columns. All data is kept, including ID = 3, and GAD7 and Employment are filled up with NA values. In this case, full_join() produces the same output as left_join(). Hypothetical scenario In the case of the student mental health data, we have seen that inner_join() and right_join() as well as left(join) and full_join() produce the same results. Can you think of a way how you would have to modify short_MH and/or extra_MH to produce different results for inner_join()/ right_join() or left(join)/full_join()? Solution Adding data for participant 269 to short_MH and 270 to extra_MH would do the trick: inner_join() would still be the same output of 267 observations since the “overlapping” ID numbers for data1 and data2 don’t change (1,2,4,5,…,268) right_join() would prioritise the right table extra_MH, leaving us with ID numbers 1,2,4,5,…,268,270 (adding to a total of 268 observations. For ID = 270, X1 would be filled with NA; ID = 3 would not be mentioned. left(join) would prioritise the left table short_MH, selecting ID rows 1:269. For ID = 3 and ID = 269 X2 would show NA. ID = 270 would not be mentioned. full_join() would add both datasets in full, showing ID values 1:270, with ID = 270 showing NA for X1, and ID = 3 and ID = 269 showing NA for X2. All visualisation for the joins were adapted from https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti. The website also provides additional information on filtering joins (semi and anti joins) that we haven’t touched upon. 4.4.2 Binding Join Verbs In contrast to mutating join verbs, binding join verbs simply combine tables without any need for matching. Dplyr provides bind_rows() and bind_cols() for combining tables by row and column respectively. When row binding, missing columns are replaced by NA values. When column binding, if the tables do not match by appropriate dimensions, an error will result. Let’s take our simple example from above and see how data1 and data2 would be merged with bind_rows() and bind_cols(). bind_rows(data1, data2) ## # A tibble: 4 x 3 ## ID X1 X2 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 &lt;NA&gt; ## 3 2 &lt;NA&gt; b1 ## 4 3 &lt;NA&gt; b2 bind_rows() takes data2 and puts it underneath data1. Notice that the binding does not “care” that we have now two rows representing ID = 2. Since X1 and X2 do not exist in data1 and data2 respectively, NA are added. bind_cols(data1, data2) ## # A tibble: 2 x 4 ## ID X1 ID1 X2 ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 1 a1 2 b1 ## 2 2 a2 3 b2 bind_cols() takes data2 and puts it right next to data1. Since the column name ID has already been taken, column 3 gets called ID1. In the case when the dimension between the dataframes do not match, bind_rows() would still work, whereas bind_cols() would produce an error message. data3 &lt;- tibble(ID = 3:5, X3 = c(&quot;c1&quot;, &quot;c2&quot;, &quot;c3&quot;)) bind_rows(data1, data2, data3) ## # A tibble: 7 x 4 ## ID X1 X2 X3 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 a1 &lt;NA&gt; &lt;NA&gt; ## 2 2 a2 &lt;NA&gt; &lt;NA&gt; ## 3 2 &lt;NA&gt; b1 &lt;NA&gt; ## 4 3 &lt;NA&gt; b2 &lt;NA&gt; ## 5 3 &lt;NA&gt; &lt;NA&gt; c1 ## 6 4 &lt;NA&gt; &lt;NA&gt; c2 ## 7 5 &lt;NA&gt; &lt;NA&gt; c3 bind_cols(data1, data3) By the way, you can merge as many data objects as you like with the binding functions, whereas in the join functions, you are limited to two. However, you could use a pipe to combine the merged dataframe with a third. example 1: bind_rows(data1, data2, data3) example 2: full_join(data1, data2) %&gt;% full_join(data3) Your turn You have finally found the missing data corresponding to ID number 3. This subject has a GAD7 score of 4 and is employed part-time. Store this information in a tibble called new_participant and bind it to the extra_MH dataset using bind_rows(). Store this merged output to your Global Environment as a new object called extra_MH_final. Solution new_participant &lt;- tibble(ID = 3, GAD7 = 4, Employment = &quot;Part&quot;) extra_MH_final &lt;- bind_rows(new_participant, extra_MH) Follow-up Question The dataset extra_MH_final now contains the same number of observations (rows) as short_MH. Use bind_cols() to merge these two datasets together in a tibble called MH_final. How many rows and columns are you expecting for MH_final to have and why? Rows (or observations): Columns (or variables): Solution MH_final &lt;- bind_cols(short_MH, extra_MH_final) We were expecting 268 observations (as both datasets have 268 rows) and 18 columns (i.e. 15 from short_MH and 3 from extra_MH_final). Notice that the ID column has been duplicated with an added suffix. Follow-up Question 2 Using your knowledge of one-table verbs, exclude the column ID1, overwriting the object MH_final. Solution MH_final &lt;- select(MH_final, -ID1) Follow-up Question 3 Rather than using bind_cols() and select(), can you think of a different way how you could have merged short_MH and extra_MH_final? Solution # One solution: MH_final &lt;- full_join(short_MH, extra_MH_final) ## Joining, by = &quot;ID&quot; Actually, any of the other joins would have worked as well, though right_join() would have sorted the column ID differently. Try it out! 4.5 Additional information Garrick Aden-Buie created some amazing gganimation gif to illustrate how the joins work. Check it out! https://www.garrickadenbuie.com/project/tidyexplain/ 4.6 Summative Homework The second summative assessment is available on moodle now. Good luck. Check that your Rmd file knits into a html file before submitting. Upload your Rmd file (not the knitted html) to moodle. "],
["data-transformation-3-finetuned-data-manipulation.html", "Chapter 5 Data Transformation 3: Finetuned Data Manipulation Intended Learning Outcomes 5.1 Pre-steps 5.2 gather() and spread() 5.3 unite() and separate() 5.4 rename() 5.5 recode() 5.6 ifelse and case_when 5.7 distinct 5.8 Additional information 5.9 Bonus: mutate rownames from the mtcars 5.10 Formative Homework", " Chapter 5 Data Transformation 3: Finetuned Data Manipulation Intended Learning Outcomes The whole purpose of this lecture is to tidy up dataframe and expose you to a bunch of useful functions that would make your daily life easier when dealing with your own data. By the end of today, you will know How to rearrange data from long format into to wide format and vice versa How to combine and separate columns How to rename column headers How to recode cell values How to mutate based on conditions How to obtain unique values from your data 5.1 Pre-steps Before we can start to focus on some other functions that might come in handy for data manipulation, we need to make sure to load tidyverse into the library and read the data we will be working with today into our Global Environment. library(tidyverse) data_SMH &lt;- read_csv(&quot;Student_Mental_Health.csv&quot;) 5.2 gather() and spread() gather() and spread() are part of tidyr (also part of the tidyverse package) and help you to rearrange the shape of your data. To get your data into long format, you would use gather(); if you wanted to get your data from long to wide format, you would need spread(). Here is a nice gif animation by Garrick Aden-Buie () that shows you how gather() and spread() work. The catch is that you need to know what kind of statistics you want to run, and how your data needs to be structured in order for you to achieve that. We cannot tell you that in this mere 10 week introduction course, however, we can give you the tools to prepare you as best as we can for what’s out there. 5.2.1 gather() We can start this lecture by looking at a practical example in the build-in dataset table1 to table5. They show the number of Tuberculosis cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000 (the full dataset is called who). The data is part of the tidyverse package, so as long as we have tidyverse loaded into the library, there should not be an issue in accessing this dataset. table1 ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table1 has a very tidy structure. You can see the data contains values associated with four variables (country, year, cases, and population). table4a however, looks a touch not right. table4a ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 Somehow the values for the columns year and cases are missing and instead we find two separate columns for 1999 and 2000 that have all cases values listed. This is a problem as 1999 and 2000 are actual values and not variables. Currently the data is in what is called a wide format. The function gather() comes in handy when we want to get the data back into the shape of a long format like in table1. gather() is structured like: Let’s apply this formula to table4a We need a dataframe that we want to modify -&gt; table4a We need to come up with the name of a new column in which the values of 1999 and 2000 will be stored -&gt; year We need to come up with the name of a new column in which all the case values will be stored -&gt; cases And finally, we need to tell R which columns in table4a we want to turn into long format (i.e. the columns of the 7 subscales) -&gt; 1999 and 2000 (Note that “1999” and “2000” are non-syntactic names as they don’t start with a letter. The solution is to surround them in backticks.) gather(table4a, key = year, value = cases, `1999`:`2000`) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 Here we have only 2 columns to reshape 1999 and 2000. We could have written gather(table4a, year, cases, `1999`, `2000`). Your turn Use the gather() function with the student mental health data data_SMH to reshape it from wide format into long format. Step 1: Only work with a selection of columns from data_SMH to see better what is going on. Create a new object SMH_short that shows only ID, and the 7 subscales of ToAS (APD:AMiscell). Step 2: use gather() according to the formula above so that the 7 subscales APD:AMiscell of SMH_short are gathered in one column named Subscales and their values in another column Scores. Store results in the Global Environment as SMH_long. Step 3: arrange() the data SMH_long by the column ID. Store the results as SMH_long. You can either overwrite SMH_long from Step 2 or use a pipe (%&gt;%). When you are done, SMH_long should look like this. ## # A tibble: 1,876 x 3 ## ID Subscales Scores ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 APD 23 ## 2 1 AHome 9 ## 3 1 APH 11 ## 4 1 Afear 8 ## 5 1 ACS 11 ## 6 1 AGuilt 2 ## 7 1 AMiscell 27 ## 8 2 APD 8 ## 9 2 AHome 7 ## 10 2 APH 5 ## # ... with 1,866 more rows Solution SMH_short &lt;- select(data_SMH, ID, APD:AMiscell) SMH_long &lt;- SMH_short %&gt;% gather(Subscales, Scores, APD:AMiscell) %&gt;% arrange(ID) SMH_long ## # A tibble: 1,876 x 3 ## ID Subscales Scores ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 APD 23 ## 2 1 AHome 9 ## 3 1 APH 11 ## 4 1 Afear 8 ## 5 1 ACS 11 ## 6 1 AGuilt 2 ## 7 1 AMiscell 27 ## 8 2 APD 8 ## 9 2 AHome 7 ## 10 2 APH 5 ## # ... with 1,866 more rows A more detailed explanation: We needed a dataframe that we want to modify -&gt; SMH_short We needed to come up with the name of a new column in which all the column headers of the 7 subscales will be stored -&gt; Subscales We needed to come up with the name of a new column in which all the cell values of the 7 subscales will be stored -&gt; Scores And finally, we needed to tell R which columns in the dataframe SMH_short we wanted to turn into long format (i.e. the columns of the 7 subscales) -&gt; APD:AMiscell SMH_short has 268 observations and 8 variables, whereas the rearranged SMH_long has 1876 observations and 3 columns - ID (which was there before) and the two new columns Subscales and Scores we created within gather(). After sorting it by ID we can see that each of the 268 participants have now 7 rows of observation - one for each subscale. 5.2.2 spread() Now onto the reverse. spread() will spread the data from long into wide format. When you have observation that are scattered across multiple rows, you can use spread() to split rows up into separate variables. For example, table2 has the variabes cases and population stored in one column type, however, they are separate variables rather than values of type. So best to get cases and population back into their own columns. table2 ## # A tibble: 12 x 4 ## country year type count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 1272915272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 Take a look how spread() achieves that. Let’s apply the formula above to table2: We need a dataframe that we want to modify -&gt; table2 We need to decide which of the columns in table2 will become the new column headers -&gt; type We need to decide which of the columns in table2 has all the data in it that will become the new cell values -&gt; count spread(table2, key = type, value = count) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 Voila, cases and population are in their own columns. Your turn Let’s pretend that the 7 subscales in SMH_long are actually 7 variables. Use spread() to achieve that. Store your results in the Global Environment as SMH_wide. When you are done, your results should look like this. ## # A tibble: 268 x 8 ## ID ACS Afear AGuilt AHome AMiscell APD APH ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 11 8 2 9 27 23 11 ## 2 2 3 4 2 7 10 8 5 ## 3 3 4 6 3 4 14 13 7 ## 4 4 6 8 4 10 21 16 10 ## 5 5 7 8 4 12 31 15 5 ## 6 6 7 8 3 8 29 18 10 ## 7 7 3 5 2 6 15 17 10 ## 8 8 11 15 6 20 40 16 19 ## 9 9 10 13 6 12 33 22 13 ## 10 10 3 12 2 4 17 8 5 ## # ... with 258 more rows Solution SMH_wide &lt;- spread(SMH_long, Subscales, Scores) A more detailed explanation We needed a dataframe that we want to modify -&gt; SMH_long We needed to decide which of the columns in SMH_long would become the new column headers -&gt; Subscales We needed to decide which of the columns in SMH_long had all the data in it that would become the new cell values -&gt; Scores Now the 7 subscales are back in separate columns each. Most of the time, data isn’t collected in a way that is useful for us (or R). It can happen that the data for the whole experiment is stored in a 2-column format. For example, some online platforms would give you a column in which all your dependent variables are stored, and another one that recorded the responses of the participants to that variable. That wouldn’t be a very useful format to analyse anything really. Let’s apply the formula above to our data and store results in the Global Environment as SMH_wide. We need a dataframe that we want to modify -&gt; SMH_long We need to decide which of the columns in SMH_long will become the new column headers -&gt; Subscales We need to decide which of the columns in SMH_long has all the data in it that will become the new cell values -&gt; Scores SMH_wide &lt;- spread(SMH_long, Subscales, Scores) SMH_wide ## # A tibble: 268 x 8 ## ID ACS Afear AGuilt AHome AMiscell APD APH ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 11 8 2 9 27 23 11 ## 2 2 3 4 2 7 10 8 5 ## 3 3 4 6 3 4 14 13 7 ## 4 4 6 8 4 10 21 16 10 ## 5 5 7 8 4 12 31 15 5 ## 6 6 7 8 3 8 29 18 10 ## 7 7 3 5 2 6 15 17 10 ## 8 8 11 15 6 20 40 16 19 ## 9 9 10 13 6 12 33 22 13 ## 10 10 3 12 2 4 17 8 5 ## # ... with 258 more rows 5.3 unite() and separate() Let’s start this part of by looking at a practical example in the build-in dataset table1 to table5. They show the number of Tuberculosis cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data is part of the tidyverse package, so as long as we have tidyverse loaded into the library, there should not be an issue in accessing this dataset. table1 ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table1 has a very tidy structure. You can see the data contains values associated with four variables (country, year, cases, and population). table5 however, looks a touch not right. table5 ## # A tibble: 6 x 4 ## country century year rate ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745/19987071 ## 2 Afghanistan 20 00 2666/20595360 ## 3 Brazil 19 99 37737/172006362 ## 4 Brazil 20 00 80488/174504898 ## 5 China 19 99 212258/1272915272 ## 6 China 20 00 213766/1280428583 Take 2 min with the person next to you to discuss what is wrong with this tibble. Solution column rate holds the values for cases and population in one cell, separated by a / the values in column year are split into century and year This is where the functions separate() and unite() come in handy. We would use separate() to split the column rate back into two columns, and unite() (the inverse of separate) to combine century and year into a single column. The function separate() is structured like this separate(data, column_to_sep, into = c(new_column1, new_column2), sep = &quot; &quot;) We would need the data in which the column to separate is located, the actual colum we want to separate, the into argument telling into how many columns we want to separate the old column and what we want to call these new columns, and a separator argument. Let’s tackle the first problem, splitting rate back into two columns cases and population/ separate(table5, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) ## # A tibble: 6 x 5 ## country century year cases population ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745 19987071 ## 2 Afghanistan 20 00 2666 20595360 ## 3 Brazil 19 99 37737 172006362 ## 4 Brazil 20 00 80488 174504898 ## 5 China 19 99 212258 1272915272 ## 6 China 20 00 213766 1280428583 We have told R to separate the column rate (which is located in table5) into two new columns cases and population. The separator argument was set to a forward slash (/), and R will put all cell information before the / into cases, and everything after the / into population. If for some reason, you wanted to keep the original column, you can set an additional argument remove to FALSE. separate(table5, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;, remove = FALSE) ## # A tibble: 6 x 6 ## country century year rate cases population ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745/19987071 745 19987071 ## 2 Afghanistan 20 00 2666/20595360 2666 20595360 ## 3 Brazil 19 99 37737/172006362 37737 172006362 ## 4 Brazil 20 00 80488/174504898 80488 174504898 ## 5 China 19 99 212258/1272915272 212258 1272915272 ## 6 China 20 00 213766/1280428583 213766 1280428583 What if you are just interested retaining part of the data in the cell, for example you want to keep the column cases but not population. The solution is to work with an NA argument. Defining the new columns as cases and NA will keep everything before the separator in the column cases, and drops everything after the separator. separate(table5, rate, into = c(&quot;cases&quot;, NA), sep = &quot;/&quot;) ## # A tibble: 6 x 4 ## country century year cases ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745 ## 2 Afghanistan 20 00 2666 ## 3 Brazil 19 99 37737 ## 4 Brazil 20 00 80488 ## 5 China 19 99 212258 ## 6 China 20 00 213766 By the way, the separator argument sep = can be anything, for example an underscore (\"_\"), comma (“,”), semi-colon (“;”), colon (“:”), forward-slash (“/”), space (\" \") or nothing (\"\"). It is also possible to separate by position. sep = 2 would split the column between the second and third character/ number etc. Technically, you would not need a separator argument in the case above, as separate() splits the data whenever it detects a non-alphanumeric character (i.e. a character that isn’t a number or letter). Saying that, the separator argument is needed when your column contains non-alphanumeric characters as part of your cell values. But watch out! When the separator is a full stop, you would need to add a double backward slash in front of it (sep = “\\\\.”). Let’s try that the separation by position. We will keep 4 letters from each country name rather than the whole word, and drop the rest. separate(table5, country, into = c(&quot;country&quot;, NA), sep = 4) ## # A tibble: 6 x 4 ## country century year rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afgh 19 99 745/19987071 ## 2 Afgh 20 00 2666/20595360 ## 3 Braz 19 99 37737/172006362 ## 4 Braz 20 00 80488/174504898 ## 5 Chin 19 99 212258/1272915272 ## 6 Chin 20 00 213766/1280428583 Yay! Notice how rate is back to one column with both values in each row since we haven’t stored any output in the Global Environment. There is only one thing left to do, and that is combining the columns century and year into a new column called year. Here, we can use the function unite() which is structured like unite(data, new_column, col_to_unite1, col_to_unite2, sep = &quot;_&quot;) We would need the data table5, a new column we want to create year, the two columns we would like to combine (century and year), and define the separator as “nothing” since the default is sep = \"_\". unite(table5, year, century, year, sep = &quot;&quot;) Right, let’s combine the two steps of tidying the table5 data by creating a pipe %&gt;% and store the new object tb_cases in the Global Environment. tb_cases &lt;- table5 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) %&gt;% unite(year, century, year, sep = &quot;&quot;) tb_cases ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 There is still a tiny bit off in the tibble above. Can you spot what it is? * Hint: Think about if you wanted to sum up all the TB cases occured in the 3 countries within the years 1999, and 2000. Solution All the columns are character columns. For any calculation however, the columns need to be numerical. The quickest solution would be to add another argument convert to separate() and set it to TRUE. tb_cases &lt;- table5 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;, convert = TRUE) %&gt;% unite(year, century, year, sep = &quot;&quot;) tb_cases ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 Unfortunately, unite() does not have a convert statement available. If you wanted to set column year as an interger, you would have to mutate the column. How would you do this? Solution tb_cases &lt;- tb_cases %&gt;% mutate(year = as.integer(year)) tb_cases ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 5.4 rename() rename() is a very useful function if we wanted to change column names. All available column names are retained, so nothing is lost. It follows a very simple pattern of rename(data, new_column_name = old_column_name) You can rename multiple column headers by including more arguments, separarting them with a comma. Let’s take a look at a simple example in table1. table1 ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 If we wanted to change the column headers of country to Country and population to Population, we would code rename(table1, Country = country, Population = population) ## # A tibble: 6 x 4 ## Country year cases Population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 If you want to select a few columns and rename them in the process, you could use select(). The structure is the same as with rename(), the only difference is that the new data only retains the columns mentioned explicitly within select(). select(data, new_column_name = old_column_name) Modifying the rename() example from above would lead to selecting the columns country and population from table1 and renaming them as Country and Population at the same time. select(table1, Country = country, Population = population) ## # A tibble: 6 x 2 ## Country Population ## &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 19987071 ## 2 Afghanistan 20595360 ## 3 Brazil 172006362 ## 4 Brazil 174504898 ## 5 China 1272915272 ## 6 China 1280428583 5.5 recode() works with mutate 5.6 ifelse and case_when in combination with mutate We can recode the Age groups… use %in% so that they can do the homework task - we did not explain that in filter 5.7 distinct The distinct() function is used to remove duplicate rows in your dataframe. If we are using distinct() without specifying any arguments, R checks the whole row and excludes any row that is exactly repeated. data_SMH_no_dup &lt;- data_SMH %&gt;% distinct() We can see that all rows are still there. This is not surprising, given every participant has a unique ID number. We could exclude the ID column to check how many full rows are exactly identical. data_SMH_no_dup &lt;- data_SMH %&gt;% select(-ID) %&gt;% distinct() We can see here that 5 rows were excluded as data_SMH_no_dup has 263 observations compared to 268 in data_SMH. distinct() does take arguments as well, namely the variable columns you are trying to determine uniqueness for. Say we we wanted to investigate how many regions are included in data_SMH. regions &lt;- data_SMH %&gt;% distinct(Region) regions ## # A tibble: 5 x 1 ## Region ## &lt;chr&gt; ## 1 SEA ## 2 EA ## 3 SA ## 4 Others ## 5 JAP We can see that there are 5 distinct regions. But what happened to the output? Now we have an overview that people were from 5 distinct regions, but we have lost all the other data in the dataframe. One quick solution would be to use the argument .keep_all and set that to TRUE (the default here is FALSE). regions &lt;- data_SMH %&gt;% distinct(Region, .keep_all = TRUE) regions ## # A tibble: 5 x 19 ## ID inter_dom Region Gender Academic Age Stay_Cate Japanese_cate ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Inter SEA Male Grad 24 Long Average ## 2 4 Inter EA Female Grad 29 Short Low ## 3 7 Inter SA Male Grad 23 Short Average ## 4 10 Inter Others Male Grad 31 Medium Low ## 5 39 Inter JAP Female Under 21 Long High ## # ... with 11 more variables: English_cate &lt;chr&gt;, ToDep &lt;dbl&gt;, ToSC &lt;dbl&gt;, ## # APD &lt;dbl&gt;, AHome &lt;dbl&gt;, APH &lt;dbl&gt;, Afear &lt;dbl&gt;, ACS &lt;dbl&gt;, ## # AGuilt &lt;dbl&gt;, AMiscell &lt;dbl&gt;, ToAS &lt;dbl&gt; In the new regions dataframe, we still have 5 rows of observations but we kept all 19 columns. If there are multiple rows with the same input (in this case 268 people came from 5 different regions), distinct() only preserves the first row a new value occurs. The distinct() function also allows you to eliminate duplicate rows with multiple variables in the dataframe. So if we wanted to see how many different regions participants were from, but also whether they are male or female, we would type… RegGen &lt;- data_SMH %&gt;% distinct(Region, Gender) RegGen ## # A tibble: 10 x 2 ## Region Gender ## &lt;chr&gt; &lt;chr&gt; ## 1 SEA Male ## 2 EA Female ## 3 SA Male ## 4 SEA Female ## 5 Others Male ## 6 Others Female ## 7 EA Male ## 8 SA Female ## 9 JAP Female ## 10 JAP Male RegGen has 10 observations, so that means, we have at least 1 male and 1 female participant from each of the 5 regions. You can see they are not sorted by either of the column. Why is that? Solution The values are sorted by occurence. R goes throgh the tibble row by row to determine whether the values are distinct from the ones in the row before. So if you look at your original dataframe data_SMH, you can see the first row is a male participant from SEA. But the participants in rows 2 and 3 are also males from SEA. The next unique value would be detected in row 4, then in row 7 (as row 5 is the same as 4, and row 6 is a repetition of row 1), then in row 8, … You can add as many variables as you like, however they need to be separated by a comma. distinct() does not take any “shortcuts” such as inter_dom:ToAS. Don’t believe it? Try it out in your Console. 5.8 Additional information More information on stuff we covered today and beyond can be found here: https://r4ds.had.co.nz “R 4 Data Science” by Garrett Grolemund and Hadley Wickham is the official guidebook for R https://suzan.rbind.io/categories/tutorial/ She has some pretty cool tutorials on data wrangling 5.9 Bonus: mutate rownames from the mtcars Remember, in lecture 2 when we were talking about the mtcars dataset and how the car types were not in listed as a separate column but rather rownames? Let’s just read in the data and have another quick look to jug our memories… df_mtcars &lt;- mtcars head(df_mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 You can see much better what I’m talking about when you view your df_mtcars. Now, that we have learnt about the mutate() function, we can attempt to get all of these rownames into a new column. All we have to do is combining a function called rownames() with mutate(). We also could use some more of these handy pipes %&gt;% you learnt about last week. df_mtcars &lt;- mtcars %&gt;% mutate(Car_type = rownames(mtcars)) In this example, we have taken the dataset mtcars, then added a new column to it with mutate() in which we wanted the new column header to be named Car_type. The column Car_type should then hold all the values that were previously listed as the rownames in the original mtcars data. head(df_mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb Car_type ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Mazda RX4 Wag ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Datsun 710 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet 4 Drive ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Hornet Sportabout ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Valiant We can now look at the data df_mtcars, and see that the new column was added at the end of the dataset. What would we have to do to make Car_type the first column in the dataframe? Answer # We could use the fuction select() df_mtcars &lt;- mtcars %&gt;% mutate(Car_type = rownames(mtcars)) %&gt;% select(Car_type, mpg:carb) head(df_mtcars) ## Car_type mpg cyl disp hp drat wt qsec vs am gear carb ## 1 Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 5.10 Formative Homework "],
["recap-1.html", "Chapter 6 Recap 1 6.1 Outline for today 6.2 In-class practice exam", " Chapter 6 Recap 1 6.1 Outline for today This lecture is structured a bit differently. First 30 min is time for you to ask any questions you have, clarify whatever you want to have clarified, etc. Then we will have an in-class practice exam that is structured fairly similar to the homework. Think about it: Either they do it themselves for 1 hour, and then we’ll go through possible solutions at the end, or run each question with guidance, as in how would you answer it, give you 5 min to think about it, then we’ll discuss. I like the idea of pair-programming (or pairs and a group of 3): give them a task to discuss and do together for a short time, then go over it as a class and discuss everyone’s thinking before repeating the process for the rest of the questions. All the time making sure they are taking notes/commenting their code and the code they get from the answer - Rebecca 6.2 In-class practice exam "],
["data-visualisation-1.html", "Chapter 7 Data Visualisation 1 Intended Learning Outcomes", " Chapter 7 Data Visualisation 1 Intended Learning Outcomes "],
["data-visualisation-2.html", "Chapter 8 Data Visualisation 2 Intended Learning Outcomes", " Chapter 8 Data Visualisation 2 Intended Learning Outcomes "],
["errors.html", "Chapter 9 Errors 9.1 Under Construction Intended Learning Outcomes 9.2 Errors: How to avoid some and live through the rest 9.3 Seeking Help 9.4 Custom Functions 9.5 Living Through Errors: How reproducible code enables science to self-correct", " Chapter 9 Errors 9.1 Under Construction This page is currently under construction and will be updated as it is written. I’m trying to write material that will suit the diverse needs of the class. Intended Learning Outcomes By the end of this session you should be: Able to debug some of the more common errors found in your code. Know where to go online to find help and continue your coding journey on your own. Be able to write a simple custom function, including one error message output for incorrect data type input. Understand why transparency and openness in data analysis is important for both scientists and the general public. 9.2 Errors: How to avoid some and live through the rest I don’t know a single person who can produce 100% correct code on the first attempt. It’s even common to produce code that runs, only for you to find out later that there were errors. Not all errors prevent code from running! How to avoid some and deal with the unavoidable. 9.2.1 Debugging A literal bug in a machine, often incorrectly cited as the source of the term “debugging”. From https://en.wikipedia.org/wiki/Debugging. 9.2.1.1 What is Debugging? 9.2.1.2 Ways to Debug 9.2.1.2.1 Messages from R 9.2.1.2.1.1 Error Messages 9.2.1.2.1.2 Warning Messages 9.2.1.2.1.3 Other Messages 9.2.2 Debugging Questions 9.3 Seeking Help 9.3.1 Searching for Help Online 9.4 Custom Functions A way to avoid copying and pasting code and introducing simple errors. 9.5 Living Through Errors: How reproducible code enables science to self-correct "],
["recap-2-before-the-final-assessment.html", "Chapter 10 Recap 2: Before the Final Assessment 10.1 Intended Learning Outcomes", " Chapter 10 Recap 2: Before the Final Assessment 10.1 Intended Learning Outcomes "],
["appendices.html", "Appendices Source Materials Further Reading", " Appendices Source Materials This course has been remixed from the following sources. If you wish to further your reading we would advise looking over these sources yourself. They are aimed at a variety of different level students, thus they may move a little faster and have greater expectations of prior knowledge. Our Level 1 Data Skills Handbook (Nordmann and Woods 2019) Further Reading Statistics More Advanced Use of R For those who are looking to read in more detail about what we have been doing in this class: R for Data Science (Grolemund and Wickham 2016) References "],
["references.html", "Chapter 11 References", " Chapter 11 References "]
]
